Time and resources of this paper are limited. Due to these limitations, metalearning, non-neural networks, other computer vision tasks, unsupervised learning, semi-supervised learning, and learning auxiliaries, i.e., transfer learning, adversarial training, data augmentation, input normalization,  weight decay, and multi-task learning, are excluded from this paper.
\par% business scenario
As stated in Section \ref{sec:motivation}, an augmented reality solution for field workers requires software perceiving the environment of field workers. This includes other computer vision tasks as well. This paper is limited to a sub-field, i.e., tool image classification.
\par% non-neural networks
The scope of this paper is to determine the best-performing neural network for tool image classification. Although neural networks are the state of the art of image classification, as image classification leaderboards show, see Section \ref{sec:benchmark}, it is possible that non-neural networks might be suitable for tool image classification as well.
\par% semi-, unsupervised, learning auxiliaries
In the experiment conducted by this paper, neural networks are trained exclusively supervised without learning auxiliaries. Supervised learning can only utilize labeled training data, while semi- and unsupervised learning can utilize unlabeled data as well. More training data and the excluded learning auxiliaries can improve performance. \autocites{Pan.2010}{Szegedy.2014}{ElAmir.2020} In consequence, the results of the experiment might be improved by implementing those methods.
\par% hyperparm/architecture search, versions of sota nns
Furthermore, in the experiment, due to limited time and resources, conducting a neural network architecture search and hyperparameter search is excluded. A method to learn neural network architectures and hyperparameters is metalearning. \autocite{Schaul.2010} Furthermore, this paper selects the state-of-the-art neural networks determined in the literature review of this paper to conduct the experiment. The literature review regards only the underlying neural network without auxiliaries. If several versions of the underlying neural network exist, the literature review regards the best-performing version according to the paper originally proposing the neural network. Thus, neural architecture search, hyperparameter search, and regarding the different versions of the state-of-the-art neural networks for image classification might reveal neural networks with which it would be worth conducting the experiment. Conducting the experiment with these neural networks might reveal even better-performing neural networks for tool image classification than found in the results of this paper. However, conducting the experiment for these neural networks requires more time and resources than available to this paper.
\par% EfficientNet
As discussed in this chapter, EfficientNet-B7 did not learn to classify tool images. On that account, the accuracy of EfficientNet-B7 reported in Chapter \ref{chp:result} cannot be interpreted as the performance of EfficientNet-B7 for tool image classification, but simply as that EfficientNet-B7 was not able to learn in the course of the experiment.
\par %Bigger Dataset
Finally, more training data can further improve performance. \autocite{ElAmir.2020} Hence, increasing the size of the \ac{TIC Dataset} might improve the accuracies reported in Chapter \ref{chp:result}. Furthermore, tool image classification comprises all classes of tools. The \ac{TIC Dataset} comprises only classes of tools that were available to this paper, i.e., drill, hammer, pliers, saw, screwdriver, and wrench. The \ac{TIC Dataset} can be extended by creating more images as described in Section \ref{sec:datasetconstruction} or adding subsets containing tool images of already existing datasets.