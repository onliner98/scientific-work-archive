The literature review consists of a preparation and an implementation phase.
In the preparation phase, literature inclusion and exclusion criteria, a literature source list, and a term table are constructed.
The inclusion and exclusion criteria determine whether or not a paper is selected for the literature review. The inclusion and exclusion criteria are listed in Section \ref{sec:krit}.
The literature source list lists all sources of papers. These sources are journals, conference proceedings, full-text databases, image classification leaderboards, and scientific search engines. The literature source list is displayed in Section \ref{sec:source}.
The term table lists terms related to the problem statement described in Section \ref{sec:problem}. As a result, the term table contains all terms that can be used to derive search queries. The term table is displayed in Section \ref{sec:termtable}.
In the implementation phase, the sources are systematically screened using the search queries. The resulting papers are selected using the inclusion and exclusion criteria. Following \cite{Webster.2002}, the selected papers are analyzed in Concept Matrix \ref{tab:concept_matrix}. The concept matrix maps each paper to concepts of neural networks they support.
\par
The state-of-the-art neural networks for image classification are selected based on these concepts. For each concept this paper determines the best-performing neural network for image classification. Performance of neural networks for image classification is measured on benchmark datasets. The benchmark datasets are listed in Section \ref{sec:benchmark}. For these datasets, neural networks are ranked on leaderboards based on accuracy. The accuracy differs for the same neural network on different leaderboards. Accordingly, different leaderboards have differently complex tasks. Thus, neural networks cannot be compared by averaging accuracy across all leaderboards. Furthermore, not every neural network is listed on every leaderboard. \autocites{imagenet.2019}{cifar.2012}{mnist.2010}{svhn.2011}{clothing.2016}{fashionMNIST.2017}{Darlow.2018}{food.2014}{vanHorn.2018}{stanfordcars.2013}{emnistletters.2017}{kuzushijiMNIST.2018}{cub.2011}{Sabour.2017}{isic1.2019}{isic2.2018}{isic3.2018} Hence, the neural networks are not comparable by averaging rank across all leaderboards. Accordingly, the neural networks are compared pairwise. A neural network $A$ is ranked above a neural network $B$ if $A$ performs better on a larger number of leaderboards that contain both $A$ and $B$.
\par
Neural networks ranked on the leaderboards use different auxiliaries to further improve performance. \autocites{Lim.2019}{Harris.2020}{Huang.2019b}{Wang.2019}{Xie.2019b}{Touvron.2019}{Darlow.2018}{Tan.2019}
As stated in Section \ref{sec:scope}, this paper focuses exclusively on the neural network. Therefore, only the underlying neural network is regarded. If several versions of the underlying neural network exist, the best-performing version according to the paper originally proposing the neural network is regarded as the best-performing state-of-the-art neural network.
\par
In summary, the result of this literature review are state-of-the-art concepts of neural networks for image classification and the best-performing state-of-the-art neural network for each concept. The results of the literature review are reported in Chapter~\ref{chp:sota}.
