% This file was created with Citavi 6.3.0.0

@misc{Kabir.2020,
	title={SpinalNet: Deep Neural Network with Gradual Input}, 
	author={H M Dipu Kabir and Moloud Abdar and Seyed Mohammad Jafar Jalali and Abbas Khosravi and Amir F Atiya and Saeid Nahavandi and Dipti Srinivasan},
	year={2020},
	eprint={2007.03347},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@misc{Foret.2020,
	title={Sharpness-Aware Minimization for Efficiently Improving Generalization}, 
	author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
	year={2020},
	eprint={2010.01412},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@proceedings{AAAI.2017,
 year = {2017},
 title = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
 publisher = {{AAAI Press}},
 series = {AAAI'17},
 editor = {{AAAI Press}}
}


@proceedings{AAAIPress.2016,
 year = {2016},
 title = {Thirtieth AAAI Conference on Artificial Intelligence},
 url = {http://www.aaai.org/Library/AAAI/aaai16contents.php},
 editor = {{AAAI Press}},
 institution = {{Association for the Advancement of Artificial Intelligence}}
}


@proceedings{ACM.2017,
 year = {2017},
 title = {Proceedings of the International Conference on Imaging, Signal Processing and Communication},
 address = {[Place of publication not identified]},
 publisher = {ACM},
 isbn = {9781450352895},
 editor = {ACM},
 doi = {10.1145/3132300},
 file = {http://www.worldcat.org/oclc/1035799630}
}


@proceedings{ACM.2017b,
 year = {2017},
 title = {Proceedings of the International Conference on Video and Image Processing},
 address = {[Place of publication not identified]},
 publisher = {ACM},
 isbn = {9781450353830},
 editor = {ACM},
 doi = {10.1145/3177404},
 file = {http://www.worldcat.org/oclc/1101332823}
}


@proceedings{ACM.2018,
 year = {2018},
 title = {ICAIP 2018: 2018 the 2nd International Conference on Advances in Image Processing : June 16-18, 2018, Chengdu, China},
 keywords = {Computer vision;Digital video;Image processing},
 address = {New York, New York},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450364607},
 series = {ICPS},
 editor = {ACM},
 institution = {{International Conference on Software Engineering and Development}},
 doi = {10.1145/3239576},
 file = {http://www.worldcat.org/oclc/1084735935}
}


@proceedings{ACM.2018b,
 year = {2018},
 title = {ISICDM 2018: Proceedings of the Second International Symposium on Image Computing and Digital Medicine : October 13-14, 2018, Chengdu, China},
 keywords = {Diagnostic imaging;Image analysis;Image processing;Medicine;Radiography, Medical},
 address = {New York, New York},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450365338},
 series = {ICPS},
 editor = {ACM},
 doi = {10.1145/3285996},
 file = {http://www.worldcat.org/oclc/1101349039}
}


@proceedings{ACM.2018c,
 year = {2018},
 title = {Proceedings of 2018 10th International Conference on Machine Learning and Computing (ICMLC 2018)},
 address = {New York, New York, USA},
 publisher = {{The Association for Computing Machinery}},
 isbn = {978-1-4503-6353-2},
 series = {ICPS},
 editor = {ACM},
 file = {http://www.worldcat.org/oclc/1062039156}
}


@proceedings{ACM.2018d,
 year = {2018},
 title = {Proceedings of ICRCA 2018: 2018 the 3rd International Conference on Robotics, Control and Automation ; ICRMV 2018 : 2018 the 3rd International Conference on Robotics and Machine Vision : Chengdu, China, August 11-13, 2018},
 keywords = {Automatic control;Automation;Computer vision;Robotics},
 address = {New York, New York},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450365307},
 series = {ICPS},
 editor = {ACM},
 institution = {{International Conference on Robotics and Machine Vision}},
 doi = {10.1145/3265639},
 file = {http://www.worldcat.org/oclc/1085512711}
}


@proceedings{ACM.2019,
 year = {2019},
 title = {IVSP 2019: Proceedings of 2019 International Conference on Image, Video and Signal Processing : Shanghai, China, February 25-28, 2019},
 keywords = {Computer vision;Digital video;Image processing;Signal processing},
 address = {New York, New York},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450361750},
 series = {ICPS},
 editor = {ACM},
 doi = {10.1145/3317640},
 file = {http://www.worldcat.org/oclc/1120938841}
}


@article{Afshar.2018,
 author = {Afshar, Parnian and Plataniotis, Konstantinos N. and Mohammadi, Arash},
 year = {2018},
 title = {Capsule Networks for Brain Tumor Classification based on MRI Images  and Course Tumor Boundaries},
 volume = {abs/1811.00597},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1811.00597}
}


@incollection{Ahmed.2019,
 author = {Ahmed, Karim and Torresani, Lorenzo},
 title = {STAR-Caps: Capsule Networks with Straight-Through Attentive Routing},
 url = {http://papers.nips.cc/paper/9110-star-caps-capsule-networks-with-straight-through-attentive-routing.pdf},
 pages = {9101--9110},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@inproceedings{AlAfandy.2019,
 author = {AlAfandy, Khalid A. and Omara, Hicham and Lazaar, Mohamed and {Al Achhab}, Mohammed},
 title = {Artificial Neural Networks Optimization and Convolution Neural Networks to Classifying Images in Remote Sensing},
 pages = {1--8},
 publisher = {ACM},
 isbn = {9781450372404},
 editor = {Lazaar, Mohamed and Duvallet, Claude and {Al Achhab}, Mohammed and Mahboub, Oussama and Silkan, Hassan},
 booktitle = {Proceedings of the 4th International Conference on Big Data and Internet of Things},
 year = {2019},
 address = {New York, NY, USA},
 doi = {10.1145/3372938.3372945},
 file = {http://dl.acm.org/doi/proceedings/10.1145/3372938}
}


@proceedings{Ali.2015,
 year = {2015},
 title = {23rd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS 2015): November 3-6, 2015 - Seattle, Washington},
 keywords = {Geographic information systems},
 address = {New York, NY},
 publisher = {{The Association for Computing Machinery, Inc}},
 isbn = {9781450339674},
 editor = {Ali, Mohamed},
 doi = {10.1145/2820783},
 file = {http://www.worldcat.org/oclc/959401155}
}


@article{Alom.2018,
 author = {Alom, Md Zahangir and Yakopcic, Chris and Taha, Tarek M. and Asari, Vijayan K.},
 year = {2018},
 title = {Breast Cancer Classification from Histopathological Images with Inception  Recurrent Residual Convolutional Neural Network},
 url = {http://arxiv.org/pdf/1811.04241v1},
 volume = {abs/1811.04241},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1811.04241}
}


@inproceedings{AlSaffar.2017,
 author = {Al-Saffar, Ahmed Ali Mohammed and Tao, Hai and Talab, Mohammed Ahmed},
 title = {Review of deep convolution neural network in image classification},
 pages = {26--31},
 publisher = {IEEE},
 isbn = {978-1-5386-3849-1},
 booktitle = {2017 International Conference on Radar, Antenna, Microwave, Electronics, and Telecommunications (ICRAMET)},
 year = {2017},
 address = {Piscataway, NJ},
 doi = {10.1109/ICRAMET.2017.8253139},
 file = {http://ieeexplore.ieee.org/document/8253139/}
}


@proceedings{Alt.2016,
 year = {2016},
 title = {MUM 2016: 15th International Conference on Mobile and Ubiquitous Multimedia : December 12-15, 2016, Rovaniemi, Finland},
 keywords = {Mobile communication systems;Multimedia communications;Ubiquitous computing},
 address = {New York},
 publisher = {ACM},
 isbn = {9781450348607},
 series = {ACM International Conference Proceeding Series},
 editor = {Alt, Florian},
 doi = {10.1145/3012709},
 file = {http://www.worldcat.org/oclc/1142751172}
}


@article{Araujo.2017,
 author = {Ara{\'u}jo, Teresa and Aresta, Guilherme and Castro, Eduardo and Rouco, Jos{\'e} and Aguiar, Paulo and Eloy, Catarina and Pol{\'o}nia, Ant{\'o}nio and Campilho, Aur{\'e}lio},
 year = {2017},
 title = {Classification of breast cancer histology images using Convolutional Neural Networks},
 keywords = {Breast Neoplasms/classification/pathology;Female;Humans;Image Processing, Computer-Assisted;Neural Networks, Computer;Support Vector Machine},
 pages = {e0177544},
 volume = {12},
 number = {6},
 journal = {PloS one},
 doi = {10.1371/journal.pone.0177544},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28570557},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5453426}
}


@article{Assiri.2019,
 author = {Assiri, Yahia Saeed},
 year = {2019},
 title = {Stochastic Optimization of Plain Convolutional Neural Networks with Simple Methods},
 url = {https://arxiv.org/abs/2001.08856},
 journal = {MLDM}
}


@proceedings{AssociationforComputingMachinery.2018,
 year = {2018},
 title = {ICISDM 2018 2nd International Conference on Information System and Data Mining : Florida Polytechnic University, Florida, USA, April 9-11, 2018},
 keywords = {Data mining;Information storage and retrieval systems;Information technology},
 address = {New York, New York},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450363549},
 series = {ICPS},
 editor = {{Association for Computing Machinery}},
 doi = {10.1145/3206098},
 file = {http://www.worldcat.org/oclc/1061559240}
}


@proceedings{AUAI.2018,
 year = {2018},
 title = {UAI},
 editor = {AUAI}
}


@inproceedings{Babaie.2017,
 author = {Babaie, Morteza and Kalra, Shivam and Sriram, Aditya and Mitcheltree, Christopher and Zhu, Shujin and Khatami, Amin and Rahnamayan, Shahryar and Tizhoosh, Hamid R.},
 title = {Classification and Retrieval of Digital Pathology Scans: A New Dataset},
 pages = {760--768},
 publisher = {IEEE},
 isbn = {978-1-5386-0733-6},
 editor = {IEEE},
 booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
 year = {2017},
 doi = {10.1109/CVPRW.2017.106},
 file = {http://ieeexplore.ieee.org/document/8014840/}
}


@proceedings{Bacchus.2017,
 year = {2017},
 title = {Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence},
 address = {California},
 publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
 isbn = {9780999241103},
 editor = {Bacchus, Fahiem and Sierra, Carles},
 doi = {10.24963/ijcai.2017}
}


@misc{Bagchi.2019,
 author = {Bagchi, Subhranil and Banerjee, Anurag and Bathula, Deepti R.},
 year = {2019},
 title = {Skin Lesion Classification using Ensemble of Stacks and Confidence Estimations of Long TailDistributions},
 url = {https://isic-challenge-stade.s3.amazonaws.com/413b79b8-97e5-47f1-bfb8-2d07d6db429e/Skin_Melanoma_Classification7.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=emptoTEfrX0fKpSY160CozFz6Aw%3D&Expires=1584573493}
}


@proceedings{Bahar.2018,
 year = {2018},
 title = {2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD): Digest of technical papers : November 5-8, 2018, Hilton San Diego Resort and Spa, San Diego, CA},
 keywords = {Computer networks;Computer-aided design;System design},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {9781450359504},
 editor = {Bahar, Iris},
 doi = {10.1145/3240765},
 file = {http://www.worldcat.org/oclc/1084482770}
}


@article{Basha.2020,
 author = {Basha, S. ShabbeerH. and Dubey, Shiv Ram and Pulabaigari, Viswanath and Mukherjee, Snehasis},
 year = {2020},
 title = {Impact of fully connected layers on performance of convolutional neural networks for image classification},
 pages = {112--119},
 volume = {378},
 issn = {09252312},
 journal = {Neurocomputing},
 doi = {10.1016/j.neucom.2019.10.008}
}


@article{Bejnordi.2017,
 abstract = {Currently, histopathological tissue examination by a pathologist represents the gold standard for breast lesion diagnostics. Automated classification of histopathological whole-slide images (WSIs) is challenging owing to the wide range of appearances of benign lesions and the visual similarity of ductal carcinoma in-situ (DCIS) to invasive lesions at the cellular level. Consequently, analysis of tissue at high resolutions with a large contextual area is necessary. We present context-aware stacked convolutional neural networks (CNN) for classification of breast WSIs into normal/benign, DCIS, and invasive ductal carcinoma (IDC). We first train a CNN using high pixel resolution to capture cellular level information. The feature responses generated by this model are then fed as input to a second CNN, stacked on top of the first. Training of this stacked architecture with large input patches enables learning of fine-grained (cellular) details and global tissue structures. Our system is trained and evaluated on a dataset containing 221 WSIs of hematoxylin and eosin stained breast tissue specimens. The system achieves an AUC of 0.962 for the binary classification of nonmalignant and malignant slides and obtains a three-class accuracy of 81.3{\%} for classification of WSIs into normal/benign, DCIS, and IDC, demonstrating its potential for routine diagnostics.},
 author = {Bejnordi, Babak Ehteshami and Zuidhof, Guido and Balkenhol, Maschenka and Hermsen, Meyke and Bult, Peter and {van Ginneken}, Bram and Karssemeijer, Nico and Litjens, Geert and {van der Laak}, Jeroen},
 year = {2017},
 title = {Context-aware stacked convolutional neural networks for classification of breast carcinomas in whole-slide histopathology images},
 pages = {044504},
 volume = {4},
 number = {4},
 issn = {2329-4302},
 journal = {Journal of medical imaging (Bellingham, Wash.)},
 doi = {10.1117/1.JMI.4.4.044504},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/29285517},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5729919}
}


@inproceedings{Belilovsky.2019,
 abstract = {Shallow supervised 1-hidden layer neural networks have a number of favorable properties that make them easier to interpret, analyze, and optimize than their deep counterparts, but lack their representational power. Here we use 1-hidden layer learning problems to sequentially build deep networks layer by layer, which can inherit properties from shallow networks. Contrary to previous approaches using shallow networks, we focus on problems where deep learning is reported as critical for success. We thus study CNNs on image classification tasks using the large-scale ImageNet dataset and the CIFAR-10 dataset. Using a simple set of ideas for architecture and training we find that solving sequential 1-hidden-layer auxiliary problems lead to a CNN that exceeds AlexNet performance on ImageNet. Extending this training methodology to construct individual layers by solving 2-and-3-hidden layer auxiliary problems, we obtain an 11-layer network that exceeds several members of the VGG model family on ImageNet, and can train a VGG-11 model to the same accuracy as end-to-end learning. To our knowledge, this is the first competitive alternative to end-to-end training of CNNs that can scale to ImageNet. We illustrate several interesting properties of these models and conduct a range of experiments to study the properties this training induces on the intermediate layers.},
 author = {Belilovsky, Eugene and Eickenberg, Michael and Oyallon, Edouard},
 title = {Greedy Layerwise Learning Can Scale To ImageNet},
 url = {http://proceedings.mlr.press/v97/belilovsky19a.html},
 pages = {583--593},
 volume = {97},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
 booktitle = {Proceedings of the 36th International Conference on Machine Learning},
 year = {2019},
 address = {Long Beach, California, USA}
}


@inproceedings{Beluch.2018,
 author = {Beluch, William H. and Genewein, Tim and N{\"u}rnberger, Andreas and K{\"o}hler, Jan M.},
 title = {The Power of Ensembles for Active Learning in Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2018}
}


@book{Bengio.2018,
 year = {2018},
 title = {Advances in Neural Information Processing Systems 31},
 publisher = {{Curran Associates, Inc}},
 editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.}
}


@article{Bentes.2018,
 author = {Bentes, Carlos and Velotto, Domenico and Tings, Bjorn},
 year = {2018},
 title = {Ship Classification in TerraSAR-X Images With Convolutional Neural Networks},
 pages = {258--266},
 volume = {43},
 number = {1},
 issn = {0364-9059},
 journal = {IEEE Journal of Oceanic Engineering},
 doi = {10.1109/JOE.2017.2767106}
}


@incollection{Berthelot.2019,
 author = {Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Papernot, Nicolas and Oliver, Avital and Raffel, Colin A.},
 title = {MixMatch: A Holistic Approach to Semi-Supervised Learning},
 url = {http://papers.nips.cc/paper/8749-mixmatch-a-holistic-approach-to-semi-supervised-learning.pdf},
 pages = {5049--5059},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@proceedings{Bhattacharyya.2019,
 year = {2019},
 title = {Proceedings, 2018 Fourth IEEE International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN): 22nd and 23rd November, 2018, Kolkata, India},
 keywords = {Computational intelligence;Telecommunication systems},
 address = {[Piscataway, New Jersey]},
 publisher = {IEEE},
 isbn = {978-1-5386-7638-7},
 editor = {Bhattacharyya, Siddhartha},
 file = {http://www.worldcat.org/oclc/1104299284}
}


@article{Blot.2016,
 author = {Blot, Michael and Cord, Matthieu and Thome, Nicolas},
 year = {2016},
 title = {Maxmin convolutional neural networks for image classification},
 volume = {abs/1610.07882},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1610.07882}
}


@article{Byerly.2020,
 author = {Byerly, Adam and Kalganova, Tatiana and Dear, Ian},
 year = {2020},
 title = {A Branching and Merging Convolutional Network with Homogeneous Filter Capsules},
 url = {https://arxiv.org/abs/2001.09136v3},
 volume = {abs/2001.0913\\6},
 journal = {ArXiv}
}


@article{Cai.2018,
 author = {Cai, Han and Zhu, Ligeng and Han, Song},
 year = {2018},
 title = {ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware},
 url = {https://arxiv.org/abs/1812.00332v2},
 journal = {ICLR 2018}
}


@book{Campilho.2018,
 year = {2018},
 title = {Image analysis and recognition15th international conference, ICIAR 2018, P{\'o}voa de Varzim, Portugal, June 27-29, 2018 : proceedings},
 keywords = {Bildanalyse;Bilderkennung;Bildverarbeitung},
 address = {Cham},
 volume = {10882},
 publisher = {Springer},
 isbn = {978-3-319-92999-6},
 series = {Lecture Notes in Computer Science},
 editor = {Campilho, Aur{\'e}lio and Karray, Fakhri and {Haar Romeny}, Bart M. ter},
 doi = {10.1007/978-3-319-93000-8}
}


@article{Castelluccio.2015,
 author = {Castelluccio, Marco and Poggi, Giovanni and Sansone, Carlo and Verdoliva, Luisa},
 year = {2015},
 title = {Land Use Classification in Remote Sensing Images by Convolutional  Neural Networks},
 volume = {abs/1508.00092},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1508.00092}
}


@inproceedings{Chagas.2018,
 author = {Chagas, Paulo and Akiyama, Rafael and Meiguins, Aruanda and Santos, Carlos and Saraiva, Filipe and Meiguins, Bianchi and Morais, Jefferson},
 title = {Evaluation of Convolutional Neural Network Architectures for Chart Image Classification},
 pages = {1--8},
 publisher = {IEEE},
 isbn = {978-1-5090-6014-6},
 booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
 year = {2018},
 address = {Piscataway, NJ, USA},
 doi = {10.1109/IJCNN.2018.8489315},
 file = {https://ieeexplore.ieee.org/document/8489315/}
}


@article{Chang.2015,
 author = {Chang, Jia-Ren and Chen, Yong-Sheng},
 year = {2015},
 title = {Batch-normalized Maxout Network in Network},
 url = {http://arxiv.org/abs/1511.02583},
 volume = {abs/1511.02583},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1511.02583}
}


@article{Chang.2017,
 author = {Chang, Jia-Ren and Chen, Yong-Sheng},
 year = {2017},
 title = {Deep Competitive Pathway Networks},
 url = {http://arxiv.org/abs/1709.10282},
 volume = {abs/1709.10282},
 journal = {CoRR}
}


@proceedings{Chaudhuri.2019,
 year = {2019},
 title = {Proceedings of the 36th International Conference on Machine Learning},
 address = {Long Beach, California, USA},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan}
}


@inproceedings{Chen.2018,
 author = {Chen, Xuan and Chen, Yufei and Ma, Chao and Liu, Xianhui and Tang, Xin},
 title = {Classification of Pancreatic Tumors based on MRI Images using 3D Convolutional Neural Networks},
 pages = {92--96},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450365338},
 series = {ICPS},
 editor = {ACM},
 booktitle = {ISICDM 2018},
 year = {2018},
 address = {New York, New York},
 doi = {10.1145/3285996.3286017},
 file = {http://dl.acm.org/citation.cfm?doid=3285996}
}


@incollection{Chen.2019,
 author = {Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K.},
 title = {This Looks Like That: Deep Learning for Interpretable Image Recognition},
 url = {http://papers.nips.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition.pdf},
 pages = {8930--8941},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@article{Chen.2019b,
 author = {Chen, Weijie and {Di Xie} and Zhang, Yuan and Pu, Shiliang},
 year = {2019},
 title = {All You Need is a Few Shifts: Designing Efficient Convolutional Neural  Networks for Image Classification},
 volume = {abs/1903.05285},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1903.05285}
}


@inproceedings{Chen.2020,
 author = {Chen, Zhuo and Zhang, Jiyuan and Ding, Ruizhou and Marculescu, Diana},
 title = {ViP: Virtual Pooling for Accelerating CNN-based Image Classification and Object Detection},
 editor = {IEEE},
 booktitle = {The IEEE Winter Conference on Applications of Computer Vision (WACV)},
 year = {2020}
}


@inproceedings{Cheng.2016,
 author = {Cheng, Gong and Ma, Chengcheng and Zhou, Peicheng and Yao, Xiwen and Han, Junwei},
 title = {Scene classification of high resolution remote sensing images using convolutional neural networks},
 pages = {767--770},
 publisher = {IEEE},
 isbn = {978-1-5090-3332-4},
 editor = {IEEE},
 booktitle = {2016 IEEE International Geoscience {\&} Remote Sensing Symposium},
 year = {2016},
 address = {Piscataway, NJ},
 doi = {10.1109/IGARSS.2016.7729193},
 file = {http://ieeexplore.ieee.org/document/7729193/}
}


@misc{Chouhan.2019,
 author = {Chouhan, Vikas},
 year = {2019},
 title = {Skin Lesion Analysis towards Melanoma Detection with Deep Convolutional Neural Network},
 url = {https://isic-challenge-stade.s3.amazonaws.com/a4760b83-1366-4957-88d2-baee36b86a7b/Skin_Lesion_Analysis_towards_Melanoma_Detection_with_Deep_Convolutional_Neural_Network.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=T%2BqURkhW72Rp2mZeW73JdkDIUJo%3D&Expires=1584572948}
}


@inproceedings{Ciresan.2011,
 author = {Ciresan, Dan C. and Meier, Ueli and Masci, Jonathan and Gambardella, Luca Maria and Schmidhuber, J{\"u}rgen},
 title = {Flexible, High Performance Convolutional Neural Networks for Image Classification},
 editor = {{World Scientific}},
 booktitle = {IJCAI},
 year = {2011}
}


@article{Ciresan.2012,
 author = {Cire{\c{s}}an, Dan and Meier, Ueli and Schmidhuber, Juergen},
 year = {2012},
 title = {Multi-column Deep Neural Networks for Image Classification},
 url = {http://arxiv.org/pdf/1202.2745.pdf},
 keywords = {Computer Science - Artificial Intelligence;Computer Science - Computer Vision and Pattern Recognition},
 journal = {CVPR 2012}
}


@article{Cubuk.2018,
 author = {Cubuk, Ekin Dogus and Zoph, Barret and Man{\'e}, Dandelion and Vasudevan, Vijay and {Le V}, Quoc},
 year = {2018},
 title = {AutoAugment: Learning Augmentation Policies from Data},
 url = {https://arxiv.org/abs/1805.09501v3},
 volume = {abs/1805.09501},
 journal = {ArXiv}
}


@inproceedings{DaoDuc.2015,
 author = {Dao-Duc, Cuong and Xiaohui, Hua and Mor{\`e}re, Olivier},
 title = {Maritime Vessel Images Classification Using Deep Convolutional Neural Networks},
 pages = {1--6},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450338431},
 series = {ICPS},
 editor = {Thang, Huynh Quyet and Phuong, Le Anh and de Raedt, Luc and Deville, Yves and Bui, Marc and Linh, Truong Thi Dieu and Oanh, Nguyen Thi and Sang, Dinh Viet and Ngoc, Nguyen Ba},
 booktitle = {SoICT 2015},
 year = {2015},
 address = {New York, New York},
 doi = {10.1145/2833258.2833266},
 file = {http://dl.acm.org/citation.cfm?doid=2833258}
}


@article{Darlow.2018,
 author = {Darlow, Luke Nicholas and Crowley, Elliot and Antoniou, Antreas and Storkey, Amos J.},
 year = {2018},
 title = {CINIC-10 is not ImageNet or CIFAR-10},
 volume = {abs/1810.03505},
 journal = {ArXiv}
}


@inproceedings{Das.2018,
 author = {Das, Arindam and Roy, Saikat and Bhattacharya, Ujjwal and Parui, Swapan K.},
 title = {Document Image Classification with Intra-Domain Transfer Learning and Stacked Generalization of Deep Convolutional Neural Networks},
 pages = {3180--3185},
 publisher = {IEEE},
 isbn = {978-1-5386-3788-3},
 editor = {IEEE},
 booktitle = {2018 24th International Conference on Pattern Recognition (ICPR)},
 year = {2018},
 doi = {10.1109/ICPR.2018.8545630},
 file = {https://ieeexplore.ieee.org/document/8545630/}
}


@proceedings{Dasgupta.2013,
 year = {2013},
 title = {Proceedings of the 30th International Conference on Machine Learning},
 address = {Atlanta, Georgia, USA},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 editor = {Dasgupta, Sanjoy and McAllester, David}
}


@misc{Dat.2019,
 author = {Dat, To Tat and Lan, Dinh Thi and Hang, Nguyen Thi Thu and Nga, Nguyen Thi Thuy and {Le Phuong}, Bich and Phuong, Nguyen Hoang and Zung, Nguyen Tien},
 year = {2019},
 title = {Multi-Step Skin Cancer Classification(ISIC 2019 Challenge Submission)},
 url = {https://isic-challenge-stade.s3.amazonaws.com/9265a61c-adf6-4ae0-b5dc-45d059e6d263/Toric_Approach_to_Skin_Cancer_Classification_2019__version_I.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=mM8rda31C13M84ZQKIyuTp8ZAmA%3D&Expires=1584572948}
}


@inproceedings{Debayle.2018,
 author = {Debayle, Johan and Hatami, Nima and Gavet, Yann},
 title = {Classification of time-series images using deep convolutional neural networks},
 url = {https://spiedigitallibrary.org/conference-proceedings-of-spie/10696/2309486/Classification-of-time-series-images-using-deep-convolutional-neural-networks/10.1117/12.2309486.full},
 pages = {23},
 publisher = {SPIE},
 isbn = {9781510619418},
 series = {Proceedings of SPIE},
 editor = {Verikas, Antanas},
 booktitle = {Tenth International Conference on Machine Vision (ICMV 2017)},
 year = {2018},
 address = {Bellingham, Washington, USA},
 doi = {10.1117/12.2309486}
}


@article{Denton.2016,
 abstract = {We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods.},
 author = {Denton, Emily and Gross, Sam and Fergus, Rob},
 year = {2016},
 title = {Semi-Supervised Learning with Context-Conditional Generative Adversarial  Networks},
 url = {http://arxiv.org/pdf/1611.06430v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1611.06430v1}
}


@article{Devries.2017,
 author = {Devries, Terrance and Taylor, Graham W.},
 year = {2017},
 title = {Improved Regularization of Convolutional Neural Networks with Cutout},
 url = {https://arxiv.org/pdf/1708.04552v2.pdf},
 volume = {abs/1708.04552},
 journal = {ArXiv}
}


@article{Dong.2017,
 author = {Dong, Xuanyi and Kang, Guoliang and Zhan, Kun and Yang, Yi},
 year = {2017},
 title = {EraseReLU: A Simple Way to Ease the Training of Deep Convolution  Neural Networks},
 url = {http://arxiv.org/abs/1709.07634},
 volume = {abs/1709.07634},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1709.07634}
}


@inproceedings{Dvornik.2019,
 author = {Dvornik, Nikita and Schmid, Cordelia and Mairal, Julien},
 title = {Diversity With Cooperation: Ensemble Methods for Few-Shot Classification},
 editor = {IEEE},
 booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 year = {2019}
}


@inproceedings{Elhoseiny.2015,
 author = {Elhoseiny, Mohamed and Huang, Sheng and Elgammal, Ahmed},
 title = {Weather classification with deep convolutional neural networks},
 pages = {3349--3353},
 publisher = {IEEE},
 isbn = {978-1-4799-8339-1},
 editor = {IEEE},
 booktitle = {2015 IEEE International Conference on Image Processing (ICIP)},
 year = {2015},
 address = {Piscataway, NJ},
 doi = {10.1109/ICIP.2015.7351424},
 file = {http://ieeexplore.ieee.org/document/7351424/}
}


@article{Esteva.2017,
 abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images-two orders of magnitude larger than previous datasets-consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
 author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
 year = {2017},
 title = {Dermatologist-level classification of skin cancer with deep neural networks},
 keywords = {Automation;Cell Phone/statistics {\&} numerical data;Datasets as Topic;Dermatologists/standards;Humans;Keratinocytes/pathology;Keratosis, Seborrheic/classification/diagnosis/pathology;Melanoma/classification/diagnosis/pathology;Neural Networks, Computer;Nevus/classification/diagnosis/pathology;Photography;Reproducibility of Results;Skin Neoplasms/classification/diagnosis/pathology},
 pages = {115--118},
 volume = {542},
 number = {7639},
 journal = {Nature},
 doi = {10.1038/nature21056},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28117445}
}


@inproceedings{Fadaeddini.2018,
 author = {Fadaeddini, Amin and Eshghi, Mohammad and Majidi, Babak},
 title = {A deep residual neural network for low altitude remote sensing image classification},
 pages = {43--46},
 publisher = {IEEE},
 isbn = {978-1-5386-2836-2},
 booktitle = {2018 6th Iranian Joint Congress on Fuzzy and Intelligent Systems (CFIS)},
 year = {2018},
 address = {Piscataway, NJ},
 doi = {10.1109/CFIS.2018.8336623},
 file = {http://ieeexplore.ieee.org/document/8336623/}
}


@book{Ferrari.2018,
 abstract = {Learning for vision -- Computational photography -- Human analysis -- Human sensing -- Stereo and reconstruction -- Optimization -- Matching and recognition -- Video attention -- Poster sessions



The sixteen-volume set comprising the LNCS volumes 11205-11220 constitutes the refereed proceedings of the 15th European Conference on Computer Vision, ECCV 2018, held in Munich, Germany, in September 2018. The 776 revised papers presented were carefully reviewed and selected from 2439 submissions. The papers are organized in topical sections on learning for vision; computational photography; human analysis; human sensing; stereo and reconstruction; optimization; matching and recognition; video attention; and poster sessions},
 year = {2018},
 title = {Computer Vision - ECCV 2018: 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part II},
 keywords = {Artificial intelligence;Computer graphics;Computer vision;Software engineering},
 address = {Cham},
 volume = {11206},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-030-01215-1},
 series = {Image Processing, Computer Vision, Pattern Recognition, and Graphics},
 editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
 doi = {10.1007/978-3-030-01216-8}
}


@book{Ferrari.2018b,
 abstract = {Learning for vision -- Computational photography -- Human analysis -- Human sensing -- Stereo and reconstruction -- Optimization -- Matching and recognition -- Video attention -- Poster sessions



The sixteen-volume set comprising the LNCS volumes 11205-11220 constitutes the refereed proceedings of the 15th European Conference on Computer Vision, ECCV 2018, held in Munich, Germany, in September 2018. The 776 revised papers presented were carefully reviewed and selected from 2439 submissions. The papers are organized in topical sections on learning for vision; computational photography; human analysis; human sensing; stereo and reconstruction; optimization; matching and recognition; video attention; and poster sessions},
 year = {2018},
 title = {Computer Vision - ECCV 2018: 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part I},
 keywords = {Artificial intelligence;Biometrics;Computer graphics;Computer vision;Optical pattern recognition},
 address = {Cham},
 volume = {11205},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-030-01245-8},
 series = {Image Processing, Computer Vision, Pattern Recognition, and Graphics},
 editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
 doi = {10.1007/978-3-030-01246-5}
}


@proceedings{Fleet.2014,
 year = {2014},
 title = {Computer Vision -- ECCV 2014},
 address = {Cham},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-319-10590-1},
 editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne}
}


@article{Fuyong.2018,
 abstract = {Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning.},
 author = {Fuyong, Xing and Yuanpu, Xie and Hai, Su and Fujun, Liu and Lin, Yang},
 year = {2018},
 title = {Deep Learning in Microscopy Image Analysis: A Survey},
 keywords = {Algorithms;Deep learning;Diagnosis, Computer-Assisted;Female;Humans;Image Processing, Computer-Assisted/methods;Male;Microscopy/methods;Neural Networks, Computer;Surveys and Questionnaires},
 pages = {4550--4568},
 volume = {29},
 number = {10},
 journal = {IEEE transactions on neural networks and learning systems},
 doi = {10.1109/TNNLS.2017.2766168},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/29989994}
}


@article{Gallego.2018,
 author = {Gallego, Antonio-Javier and Pertusa, Antonio and Gil, Pablo},
 year = {2018},
 title = {Automatic Ship Classification from Optical Aerial Images with Convolutional Neural Networks},
 pages = {511},
 volume = {10},
 number = {4},
 journal = {Remote Sensing},
 doi = {10.3390/rs10040511}
}


@article{Gao.2017,
 abstract = {Efficient Human Epithelial-2 cell image classification can facilitate the diagnosis of many autoimmune diseases. This paper proposes an automatic framework for this classification task, by utilizing the deep convolutional neural networks (CNNs) which have recently attracted intensive attention in visual recognition. In addition to describing the proposed classification framework, this paper elaborates several interesting observations and findings obtained by our investigation. They include the important factors that impact network design and training, the role of rotation-based data augmentation for cell images, the effectiveness of cell image masks for classification, and the adaptability of the CNN-based classification system across different datasets. Extensive experimental study is conducted to verify the above findings and compares the proposed framework with the well-established image classification models in the literature. The results on benchmark datasets demonstrate that 1) the proposed framework can effectively outperform existing models by properly applying data augmentation, 2) our CNN-based framework has excellent adaptability across different datasets, which is highly desirable for cell image classification under varying laboratory settings. Our system is ranked high in the cell image classification competition hosted by ICPR 2014.},
 author = {Gao, Zhimin and Wang, Lei and Zhou, Luping and Zhang, Jianjia},
 year = {2017},
 title = {HEp-2 Cell Image Classification With Deep Convolutional Neural Networks},
 keywords = {Algorithms;Cell Line;Coloring Agents;Epithelial Cells/cytology;Fluorescent Antibody Technique, Indirect/methods;Humans;Image Processing, Computer-Assisted/methods;Neural Networks, Computer;Pattern Recognition, Automated/methods},
 pages = {416--428},
 volume = {21},
 number = {2},
 journal = {IEEE journal of biomedical and health informatics},
 doi = {10.1109/JBHI.2016.2526603},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/26887016}
}


@article{Gao.2019,
 abstract = {Representing features at multiple scales is of great importance for numerous vision tasks. Recent advances in backbone convolutional neural networks (CNNs) continually demonstrate stronger multi-scale representation ability, leading to consistent performance gains on a wide range of applications. However, most existing methods represent the multi-scale features in a layer-wise manner. In this paper, we propose a novel building block for CNNs, namely Res2Net, by constructing hierarchical residual-like connections within one single residual block. The Res2Net represents multi-scale features at a granular level and increases the range of receptive fields for each network layer. The proposed Res2Net block can be plugged into the state-of-the-art backbone CNN models, e.g., ResNet, ResNeXt, and DLA. We evaluate the Res2Net block on all these models and demonstrate consistent performance gains over baseline models on widely-used datasets, e.g., CIFAR-100 and ImageNet. Further ablation studies and experimental results on representative computer vision tasks, i.e., object detection, class activation mapping, and salient object detection, further verify the superiority of the Res2Net over the state-of-the-art baseline methods. The source code and trained models are available on https://mmcheng.net/res2net/.},
 author = {Gao, Shanghua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip H. S.},
 year = {2019},
 title = {Res2Net: A New Multi-scale Backbone Architecture},
 journal = {IEEE transactions on pattern analysis and machine intelligence},
 doi = {10.1109/TPAMI.2019.2938758},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/31484108}
}


@inproceedings{Garud.2017,
 author = {Garud, Hrushikesh and Karri, S. P. K. and Sheet, Debdoot and Chatterjee, Jyotirmoy and Mahadevappa, Manjunatha and Ray, Ajoy K. and Ghosh, Arindam and Maity, Ashok K.},
 title = {High-Magnification Multi-Views Based Classification of Breast Fine Needle Aspiration Cytology Cell Samples Using Fusion of Decisions From Deep Convolutional Networks},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
 year = {2017}
}


@article{Gastaldi.2017,
 author = {Gastaldi, Xavier},
 year = {2017},
 title = {Shake-Shake regularization},
 url = {https://arxiv.org/abs/1705.07485},
 volume = {abs/1705.07485},
 journal = {ArXiv}
}


@misc{Gessert.2019,
 author = {Gessert, Nils and Nielsen, Maximilian and Shaikh, Mohsin and Werner, Ren{\'e} and Schlaefer, Alexander},
 year = {2019},
 title = {Skin Lesion Classification Using Loss Balancingand Ensembles of Multi-Resolution EfficientNets},
 url = {https://isic-challenge-stade.s3.amazonaws.com/99bdfa5c-4b6b-4c3c-94c0-f614e6a05bc4/method_description.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=er5ZkUCnrEHVZlbRvck1%2BamRz%2F8%3D&Expires=1584572948}
}


@article{Gong.2020,
 abstract = {We propose \emph{MaxUp}, an embarrassingly simple, highly effective technique for improving the generalization performance of machine learning models, especially deep neural networks. The idea is to generate a set of augmented data with some random perturbations or transforms and minimize the maximum, or worst case loss over the augmented data. By doing so, we implicitly introduce a smoothness or robustness regularization against the random perturbations, and hence improve the generation performance. For example, in the case of Gaussian perturbation,  \emph{MaxUp} is asymptotically equivalent to using the gradient norm of the loss as a penalty to encourage smoothness. We test \emph{MaxUp} on a range of tasks, including image classification, language modeling, and adversarial certification, on which \emph{MaxUp} consistently outperforms the existing best baseline methods, without introducing substantial computational overhead. In particular, we improve ImageNet classification from the state-of-the-art top-1 accuracy {\$}85.5\%$ without extra data to {\$}85.8\%$. Code will be released soon.},
 author = {Gong, Chengyue and Ren, Tongzheng and Ye, Mao and Liu, Qiang},
 year = {2020},
 title = {MaxUp: A Simple Way to Improve Generalization of Neural Network Training},
 url = {http://arxiv.org/pdf/2002.09024v1},
 keywords = {Computer Science - Learning;Statistics - Machine Learning},
 journal = {CoRR},
 file = {http://arxiv.org/abs/2002.09024v1}
}


@inproceedings{Gowal.2019,
 author = {Gowal, Sven and Dvijotham, Krishnamurthy and Stanforth, Robert and Bunel, Rudy and Qin, Chongli and Uesato, Jonathan and Arandjelovic, Relja and Mann, Timothy and Kohli, Pushmeet},
 title = {Scalable Verified Training for Provably Robust Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 year = {2019}
}


@inproceedings{Guo.2017,
 author = {Guo, Tianmei and Dong, Jiwen and Li, Henjian and Gao, Yunxing},
 title = {Simple convolutional neural network on image classification},
 pages = {721--724},
 publisher = {IEEE},
 isbn = {978-1-5090-3618-9},
 editor = {IEEE},
 booktitle = {2017 IEEE 2nd International Conference on Big Data Analysis (ICBDA 2017)},
 year = {2017},
 address = {Piscataway, NJ},
 doi = {10.1109/ICBDA.2017.8078730},
 file = {http://ieeexplore.ieee.org/document/8078730/}
}


@inproceedings{Guo.2018,
 author = {Guo, Yanhui and Ashour, Amira S. and Si, Lei and Mandalaywala, Deep P.},
 title = {Multiple Convolutional Neural Network for Skin Dermoscopic Image Classification},
 pages = {365--369},
 publisher = {IEEE},
 isbn = {978-1-5386-7568-7},
 editor = {IEEE},
 booktitle = {2018 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)},
 year = {2018},
 address = {[Piscataway, New Jersey]},
 doi = {10.1109/ISSPIT.2018.8642669},
 file = {https://ieeexplore.ieee.org/document/8642669/}
}


@inproceedings{Gurnani.2019,
 author = {Gurnani, A. and Shah, K. and Gajjar, V. and Mavani, V. and Khandhediya, Y.},
 title = {SAF-BAGE: Salient Approach for Facial Soft-Biometric Classification - Age, Gender, and Facial Expression},
 keywords = {biometrics (access control);Bounding Box margin;CNN;convolutional neural nets;Convolutional Neural Networks predictions;Deep Multilevel Network;face recognition;Facial Expression classification;Facial Expression soft-biometric;facial images;Facial soft-biometric classification;feature extraction;Gender classification;human visual system;image classification;input cropped face;ML-Net;multiplied reweighted salient face;off-the-shelf face detector;reweighted ratio;SAF-BAGE;saliency map;salient approach;test image},
 pages = {839--847},
 editor = {Winter},
 booktitle = {2019 IEEE Winter Conference on Applications of Computer Vision (WACV)},
 year = {2019},
 doi = {10.1109/WACV.2019.00094}
}


@book{H.Wallach.2019,
 year = {2019},
 title = {Advances in Neural Information Processing Systems 32},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}}
}


@book{H.Wallach.2019b,
 year = {2019},
 title = {Advances in Neural Information Processing Systems 32},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}}
}


@book{H.Wallach.2019c,
 year = {2019},
 title = {Advances in Neural Information Processing Systems 32},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}}
}


@book{H.Wallach.2019d,
 year = {2019},
 title = {Advances in Neural Information Processing Systems 32},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}}
}


@incollection{Hahn.2019,
 author = {Hahn, Taeyoung and Pyeon, Myeongjang and Kim, Gunhee},
 title = {Self-Routing Capsule Networks},
 url = {http://papers.nips.cc/paper/8982-self-routing-capsule-networks.pdf},
 pages = {7658--7667},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@article{Hang.2019,
 author = {Hang, Renlong and Liu, Qingshan and Hong, Danfeng and Ghamisi, Pedram},
 year = {2019},
 title = {Cascaded Recurrent Neural Networks for Hyperspectral Image Classification},
 pages = {5384--5394},
 volume = {57},
 number = {8},
 issn = {0196-2892},
 journal = {IEEE Transactions on Geoscience and Remote Sensing},
 doi = {10.1109/TGRS.2019.2899129}
}


@proceedings{Hanjalic.2016,
 year = {2016},
 title = {MM'16 Proceedings of the 2016 ACM Multimedia Conference : October 15-19, 2016, Amsterdam, The Netherlands},
 address = {New York, NY},
 publisher = {{ACM Association for Computing Machinery}},
 isbn = {9781450336031},
 editor = {Hanjalic, Alan and Snoek, Cees and Worring, Marcel and Bulterman, Dick and Huet, Benoit and Kelliher, Aisling and Kompatsiaris, Yiannis and Li, Jin},
 institution = {{ACM Multimedia Conference} and {Association for Computing Machinery} and {ACM Multimedia} and MM},
 doi = {10.1145/2964284},
 file = {http://www.gbv.de/dms/tib-ub-hannover/887416764.pdf}
}


@article{Harangi.2018,
 abstract = {Skin cancer is a major public health problem with over 123,000 newly diagnosed cases worldwide in every year. Melanoma is the deadliest form of skin cancer, responsible for over 9000 deaths in the United States each year. Thus, reliable automatic melanoma screening systems would provide a great help for clinicians to detect the malignant skin lesions as early as possible. In the last five years, the efficiency of deep learning-based methods increased dramatically and their performances seem to outperform conventional image processing methods in classification tasks. However, this type of machine learning-based approaches have a main drawback, namely they require thousands of labeled images per classes for their training. In this paper, we investigate how we can create an ensemble of deep convolutional neural networks to improve further their individual accuracies in the task of classifying dermoscopy images into the three classes melanoma, nevus, and seborrheic keratosis when we have no opportunity to train them on adequate number of annotated images. To achieve high classification accuracy, we fuse the outputs of the classification layers of four different deep neural network architectures. More specifically, we propose the aggregation of robust convolutional neural networks (CNNs) into one framework, where the final classification is achieved based on the weighted output of the member CNNs. For aggregation, we consider different fusion-based methods and select the best performing one for this problem. Our experimental results also prove that the creation of an ensemble of different neural networks is a meaningful approach, since each of the applied fusion strategies outperforms the individual networks regarding classification accuracy. The average area under the receiver operating characteristic curve has been found to be 0.891 for the 3-class classification task. For an objective evaluation of our approach, we have tested its performance on the official test database of the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 challenge on Skin Lesion Analysis Towards Melanoma Detection dedicated to skin cancer recognition.},
 author = {Harangi, Balazs},
 year = {2018},
 title = {Skin lesion classification with ensembles of deep convolutional neural networks},
 keywords = {Algorithms;Databases, Factual;Dermoscopy/methods;Diagnosis, Computer-Assisted/methods;Humans;Image Processing, Computer-Assisted/methods;Keratosis, Seborrheic/diagnostic imaging;Machine learning;Melanocytes/pathology;Melanoma/diagnostic imaging;Neural Networks, Computer;Nevus/diagnostic imaging;ROC Curve;Skin Neoplasms/diagnostic imaging},
 pages = {25--32},
 volume = {86},
 journal = {Journal of biomedical informatics},
 doi = {10.1016/j.jbi.2018.08.006},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/30103029}
}


@article{Harris.2020,
 abstract = {Mixed Sample Data Augmentation (MSDA) has received increasing attention in recent years, with many successful variants such as MixUp and CutMix. Following insight on the efficacy of CutMix in particular, we propose FMix, an MSDA that uses binary masks obtained by applying a threshold to low frequency images sampled from Fourier space. FMix improves performance over MixUp and CutMix for a number of state-of-the-art models across a range of data sets and problem settings. We go on to analyse MixUp, CutMix, and FMix from an information theoretic perspective, characterising learned models in terms of how they progressively compress the input with depth. Ultimately, our analyses allow us to decouple two complementary properties of augmentations, and present a unified framework for reasoning about MSDA. Code for all experiments is available at https://github.com/ecs-vlc/FMix.},
 author = {Harris, Ethan and Marcu, Antonia and Painter, Matthew and Niranjan, Mahesan and Pr{\"u}gel-Bennett, Adam and Hare, Jonathon},
 year = {2020},
 title = {Understanding and Enhancing Mixed Sample Data Augmentation},
 url = {http://arxiv.org/pdf/2002.12047v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Information Theory;Computer Science - Learning;Mathematics - Information Theory;Statistics - Machine Learning},
 journal = {CoRR},
 file = {http://arxiv.org/abs/2002.12047v1}
}


@article{Hasanpour.2016,
 author = {HasanPour, Seyyed Hossein and Rouhani, Mohammad and Fayyaz, Mohsen and Sabokrou, Mohammad},
 year = {2016},
 title = {Lets keep it simple, Using simple architectures to outperform deeper  and more complex architectures},
 volume = {abs/1608.060\\37},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1608.06037}
}


@inproceedings{He.2015,
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
 editor = {IEEE},
 booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 year = {2015}
}


@article{He.2015b,
 abstract = {Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224 $\times$ 224) input image. This requirement is {\textquotedbl}artificial{\textquotedbl} and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, {\textquotedbl}spatial pyramid pooling{\textquotedbl}, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 $\times$ faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank {\#}2 in object detection and {\#}3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.},
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 year = {2015},
 title = {Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition},
 pages = {1904--1916},
 volume = {37},
 number = {9},
 journal = {IEEE transactions on pattern analysis and machine intelligence},
 doi = {10.1109/TPAMI.2015.2389824},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/26353135}
}


@inproceedings{He.2016,
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 title = {Deep Residual Learning for Image Recognition},
 pages = {770--778},
 publisher = {IEEE},
 isbn = {978-1-4673-8851-1},
 editor = {IEEE},
 booktitle = {29th IEEE Conference on Computer Vision and Pattern Recognition},
 year = {2016},
 address = {Piscataway, NJ},
 doi = {10.1109/CVPR.2016.90},
 file = {http://ieeexplore.ieee.org/document/7780459/}
}


@article{He.2018,
 author = {He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
 year = {2018},
 title = {Bag of Tricks for Image Classification with Convolutional Neural Networks},
 url = {http://arxiv.org/pdf/1812.01187.pdf},
 volume = {abs/1812.01187},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1812.01187}
}


@inproceedings{Hori.2016,
 author = {Hori, Kazunori and Okada, Shogo and Nitta, Katsumi},
 title = {Fashion image classification on mobile phones using layered deep convolutional neural networks},
 pages = {359--361},
 publisher = {ACM},
 isbn = {9781450348607},
 series = {ACM International Conference Proceeding Series},
 editor = {Alt, Florian},
 booktitle = {MUM 2016},
 year = {2016},
 address = {New York},
 doi = {10.1145/3012709.3016075},
 file = {http://dl.acm.org/citation.cfm?doid=3012709}
}


@article{Howard.2013,
 author = {Howard, Andrew G.},
 year = {2013},
 title = {Some Improvements on Deep Convolutional Neural Network Based Image Classification},
 url = {https://arxiv.org/abs/1312.5402},
 volume = {abs/1312.5402},
 journal = {CoRR}
}


@inproceedings{Hu.2018,
 author = {Hu, Jie and Shen, Li and Sun, Gang},
 title = {Squeeze-and-Excitation Networks},
 pages = {7132--7141},
 publisher = {IEEE},
 isbn = {978-1-5386-6420-9},
 editor = {IEEE},
 booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 year = {2018},
 address = {Piscataway, NJ},
 doi = {10.1109/CVPR.2018.00745},
 file = {https://ieeexplore.ieee.org/document/8578843/}
}


@inproceedings{Huang.2017,
 author = {Huang, Gao and Liu, Zhuang and {van der Maaten}, Laurens and Weinberger, Kilian Q.},
 title = {Densely Connected Convolutional Networks},
 pages = {2261--2269},
 publisher = {IEEE},
 isbn = {978-1-5386-0457-1},
 editor = {IEEE},
 booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2017},
 doi = {10.1109/CVPR.2017.243},
 file = {http://ieeexplore.ieee.org/document/8099726/}
}


@incollection{Huang.2019,
 author = {Huang, Siyuan and Chen, Yixin and Yuan, Tao and Qi, Siyuan and Zhu, Yixin and Zhu, Song-Chun},
 title = {PerspectiveNet: 3D Object Detection from a Single RGB Image via Perspective Points},
 url = {http://papers.nips.cc/paper/9093-perspectivenet-3d-object-detection-from-a-single-rgb-image-via-perspective-points.pdf},
 pages = {8905--8917},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@incollection{Huang.2019b,
 author = {Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V. and Wu, Yonghui and Chen, zhifeng},
 title = {GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism},
 url = {http://papers.nips.cc/paper/8305-gpipe-efficient-training-of-giant-neural-networks-using-pipeline-parallelism.pdf},
 pages = {103--112},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@book{I.Guyon.2017,
 year = {2017},
 title = {Advances in Neural Information Processing Systems 30},
 publisher = {{Curran Associates, Inc}},
 editor = {{I. Guyon} and {U. V. Luxburg} and {S. Bengio} and {H. Wallach} and {R. Fergus} and {S. Vishwanathan} and {R. Garnett}}
}


@proceedings{ICLR.2018,
 year = {2018},
 title = {6th International Conference on Learning Representations, ICLR 2018,  Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
 publisher = {OpenReview.net},
 editor = {ICLR}
}


@proceedings{ICML.2019,
 year = {2019},
 title = {2019 International Conference on Machine Learning (ICML)},
 editor = {ICML}
}


@proceedings{ICRAMET.2017,
 year = {2017},
 title = {2017 International Conference on Radar, Antenna, Microwave, Electronics, and Telecommunications (ICRAMET): 23-24 October, 2017, Jakarta, Indonesia : proceeding},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5386-3849-1},
 institution = {ICRAMET and {Institute of Electrical and Electronics Engineers} and {International Conference on Radar, Antenna, Microwave, Electronics, and Telecommunications} and {Indonesia Science Expo} and ISE}
}


@proceedings{IEEE.2015,
 year = {2015},
 title = {2015 IEEE Conference on Computer Vision and Pattern Recognition workshops (CVPRW): 7 - 12 June 2015, Boston, MA},
 keywords = {Computer vision;Congresses;Maschinelles Sehen;Mustererkennung;Optical pattern recognition;Pattern recognition systems},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4673-6759-2},
 editor = {IEEE},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE Conference on Computer Vision and Pattern Recognition} and CVPR and CVPRW}
}


@proceedings{IEEE.2015b,
 year = {2015},
 title = {2015 IEEE International Conference on Image Processing (ICIP): 27 - 30 Sept. 2015, Qu{\'e}bec City, Canada},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4799-8339-1},
 editor = {IEEE},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE Signal Processing Society} and {IEEE International Conference on Image Processing} and ICIP}
}


@proceedings{IEEE.2015c,
 year = {2015},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 editor = {IEEE}
}


@proceedings{IEEE.2015d,
 year = {2015},
 title = {The IEEE International Conference on Computer Vision (ICCV)},
 editor = {IEEE}
}


@proceedings{IEEE.2015e,
 year = {2015},
 title = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 publisher = {IEEE},
 isbn = {978-1-4673-6964-0},
 editor = {IEEE}
}


@proceedings{IEEE.2016,
 year = {2016},
 title = {2016 IEEE International Geoscience {\&} Remote Sensing Symposium: Proceedings : July 10-15, 2016, Beijing, China},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5090-3332-4},
 editor = {IEEE},
 institution = {{IEEE International Geoscience {\&} Remote Sensing Symposium} and {Institute of Electrical and Electronics Engineers} and {IEEE Geoscience and Remote Sensing Society} and {IEEE International Geoscience and Remote Sensing Symposium} and IGARSS}
}


@proceedings{IEEE.2016b,
 year = {2016},
 title = {2016 International Joint Conference on Neural Networks (IJCNN): 24-29 July 2016, Vancouver, Canada},
 keywords = {Congresses;ilmpub;Neural networks (Computer science)},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5090-0620-5},
 editor = {IEEE},
 institution = {{International Joint Conference on Neural Networks} and {Institute of Electrical and Electronics Engineers} and {IEEE Computational Intelligence Society} and {International Neural Network Society} and IJCNN and {IEEE World Congress on Computational Intelligence} and {IEEE WCCI}}
}


@proceedings{IEEE.2016c,
 year = {2016},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 editor = {IEEE}
}


@proceedings{IEEE.2016d,
 year = {2016},
 title = {29th IEEE Conference on Computer Vision and Pattern Recognition: CVPR 2016 : proceedings : 26 June-1 July 2016, Las Vegas, Nevada},
 keywords = {Maschinelles Sehen;Mustererkennung},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4673-8851-1},
 editor = {IEEE},
 institution = {{IEEE Conference on Computer Vision and Pattern Recognition} and {Institute of Electrical and Electronics Engineers} and CVPR}
}


@proceedings{IEEE.2017,
 year = {2017},
 title = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 publisher = {IEEE},
 isbn = {978-1-5386-0457-1},
 editor = {IEEE}
}


@proceedings{IEEE.2017b,
 year = {2017},
 title = {2017 IEEE 2nd International Conference on Big Data Analysis (ICBDA 2017): March 10-12, 2017, Beijing, China},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5090-3618-9},
 editor = {IEEE},
 institution = {{IEEE International Conference on Big Data Analysis} and {Institute of Electrical and Electronics Engineers} and ICBDA}
}


@proceedings{IEEE.2017c,
 year = {2017},
 title = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
 publisher = {IEEE},
 isbn = {978-1-5090-4117-6},
 editor = {IEEE}
}


@proceedings{IEEE.2017d,
 year = {2017},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 editor = {IEEE}
}


@proceedings{IEEE.2017e,
 year = {2017},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
 editor = {IEEE}
}


@proceedings{IEEE.2017f,
 year = {2017},
 title = {2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
 publisher = {IEEE},
 isbn = {978-1-5386-0733-6},
 editor = {IEEE}
}


@proceedings{IEEE.2018,
 year = {2018},
 title = {2018 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)},
 keywords = {Information technology;Signal processing;Wireless communication systems},
 address = {[Piscataway, New Jersey]},
 publisher = {IEEE},
 isbn = {978-1-5386-7568-7},
 editor = {IEEE},
 file = {http://www.worldcat.org/oclc/1104313950}
}


@proceedings{IEEE.2018b,
 year = {2018},
 title = {2018 24th International Conference on Pattern Recognition (ICPR)},
 publisher = {IEEE},
 isbn = {978-1-5386-3788-3},
 editor = {IEEE}
}


@proceedings{IEEE.2018c,
 year = {2018},
 title = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition: CVPR 2018 : proceedings : 18-22 June 2018, Salt Lake City, Utah},
 keywords = {Maschinelles Sehen;Mustererkennung},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5386-6420-9},
 editor = {IEEE},
 institution = {{IEEE/CVF Conference on Computer Vision and Pattern Recognition} and {Institute of Electrical and Electronics Engineers} and {Computer Vision Foundation} and CVPR}
}


@proceedings{IEEE.2018d,
 year = {2018},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 editor = {IEEE}
}


@proceedings{IEEE.2018e,
 year = {2018},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 editor = {IEEE}
}


@proceedings{IEEE.2019,
 year = {2019},
 title = {IJCNN 2019: International Joint Conference on Neural Networks : Budapest, Hungary, 14-19 July 2019},
 keywords = {Neural networks (Computer science)},
 address = {[Piscataway, New Jersey]},
 publisher = {[IEEE]},
 isbn = {978-1-7281-1985-4},
 editor = {IEEE},
 file = {http://www.worldcat.org/oclc/1122932452}
}


@proceedings{IEEE.2019b,
 year = {2019},
 title = {2019 Scientific Meeting on Electrical-Electronics {\&} Biomedical Engineering and Computer Science (EBBT)},
 publisher = {IEEE},
 isbn = {978-1-7281-1013-4},
 editor = {IEEE},
 file = {http://www.worldcat.org/oclc/1125932733}
}


@proceedings{IEEE.2019c,
 year = {2019},
 title = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
 publisher = {IEEE},
 isbn = {978-1-7281-4803-8},
 editor = {IEEE},
 doi = {10.1109/ICCV43118.2019},
 file = {https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8972782}
}


@proceedings{IEEE.2019d,
 year = {2019},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
 editor = {IEEE}
}


@proceedings{IEEE.2019e,
 year = {2019},
 title = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
 editor = {IEEE}
}


@proceedings{IEEE.2019f,
 year = {2019},
 title = {The IEEE International Conference on Computer Vision (ICCV)},
 editor = {IEEE}
}


@proceedings{IEEE.2020,
 year = {2020},
 title = {The IEEE Winter Conference on Applications of Computer Vision (WACV)},
 editor = {IEEE}
}


@proceedings{IEEEInternationalConferenceonBigDataAnalysis.2018,
 year = {2018},
 title = {2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA 2018): March 09-12, 2018, Shanghai, China},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5386-4794-3},
 institution = {{IEEE International Conference on Big Data Analysis} and {Institute of Electrical and Electronics Engineers} and ICBDA}
}


@proceedings{IEEEInternationalConferenceonImageProcessing.2018,
 year = {2018},
 title = {2018 IEEE International Conference on Image Processing: Proceedings : October 7-10, 2018, Megaron Athens International Conference Centre, Athens, Greece},
 keywords = {ilmpub},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4799-7061-2},
 institution = {{IEEE International Conference on Image Processing} and {Institute of Electrical and Electronics Engineers} and {IEEE Signal Processing Society} and ICIP}
}


@article{Iesmantas.2018,
 author = {Iesmantas, Tomas and Alzbutas, Robertas},
 year = {2018},
 title = {Convolutional capsule network for classification of breast cancer  histology images},
 volume = {abs/1804.08376},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1804.08376}
}


@proceedings{IJCNN.2018,
 year = {2018},
 title = {2018 International Joint Conference on Neural Networks (IJCNN): 2018 proceedings},
 keywords = {ilmpub},
 address = {Piscataway, NJ, USA},
 publisher = {IEEE},
 isbn = {978-1-5090-6014-6},
 institution = {IJCNN and {IEEE Computational Intelligence Society} and {International Neural Network Society} and {Institute of Electrical and Electronics Engineers} and {International Joint Conference on Neural Networks} and {IEEE World Congress on Computational Intelligence (IEEE WCCI)}}
}


@proceedings{InstituteofElectricalandElectronicsEngineers.2015,
 year = {2015},
 title = {2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI): 16 - 19 April 2015, New York, NY},
 keywords = {Bildgebendes Verfahren;Congresses;Diagnostic imaging;Image processing;Imaging systems in medicine;Medizin},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4799-2374-8},
 institution = {{Institute of Electrical and Electronics Engineers} and {IEEE Signal Processing Society} and {IEEE Engineering in Medicine and Biology Society} and {IEEE International Symposium on Biomedical Imaging} and {IEEE International Symposium on Biomedical Imaging: From Nano to Macro} and ISBI}
}


@proceedings{InternationalConferenceonImageProcessingTheoryToolsandApplications.2017,
 year = {2017},
 title = {Proceedings of the Seventh International Conference on Image Processing Theory, Tools and Applications - IPTA 2017: Montreal, Canada, November 28-December 1},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5386-1842-4},
 institution = {{International Conference on Image Processing Theory, Tools and Applications} and {Institute of Electrical and Electronics Engineers} and {European Association for Signal Processing} and IPTA}
}


@article{Ioannou.2015,
 author = {Ioannou, Yani and Robertson, Duncan P. and Shotton, Jamie and Cipolla, Roberto and Criminisi, Antonio},
 year = {2015},
 title = {Training CNNs with Low-Rank Filters for Efficient Image Classification},
 volume = {abs/1511.06744},
 journal = {CoRR}
}


@proceedings{IranianJointCongressonFuzzyandIntelligentSystems.2018,
 year = {2018},
 title = {2018 6th Iranian Joint Congress on Fuzzy and Intelligent Systems (CFIS): 28 February-2 March 2018, Kerman, Iran},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5386-2836-2},
 institution = {{Iranian Joint Congress on Fuzzy and Intelligent Systems} and CFIS}
}


@inproceedings{Izmailov.2018,
 author = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry P. and Wilson, Andrew Gordon},
 title = {Averaging Weights Leads to Wider Optima and Better Generalization},
 editor = {AUAI},
 booktitle = {UAI},
 year = {2018}
}


@article{Jayasundara.2019,
 author = {Jayasundara, Vinoj and Jayasekara, Sandaru and Jayasekara, Hirunima and Rajasegaran, Jathushan and Seneviratne, Suranga and Rodrigo, Ranga},
 year = {2019},
 title = {TextCaps: Handwritten Character Recognition With Very Small Datasets},
 url = {https://arxiv.org/abs/1904.08095v1},
 pages = {254--262},
 journal = {2019 IEEE Winter Conference on Applications of Computer Vision (WACV)}
}


@inproceedings{Jeon.2017,
 author = {Jeon, Yunho and Kim, Junmo},
 title = {Active Convolution: Learning the Shape of Convolution for Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2017}
}


@inproceedings{Ji.2019,
 author = {Ji, Xu and Vedaldi, Andrea and Henriques, Joao},
 title = {Invariant Information Clustering for Unsupervised Image Classification and Segmentation},
 pages = {9864--9873},
 publisher = {IEEE},
 isbn = {978-1-7281-4803-8},
 editor = {IEEE},
 booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
 year = {2019},
 doi = {10.1109/ICCV.2019.00996},
 file = {https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8972782}
}


@incollection{JimenezSanchez.2018,
 author = {Jim{\'e}nez-S{\'a}nchez, Amelia and Albarqouni, Shadi and Mateus, Diana},
 title = {Capsule Networks Against Medical Imaging Data Challenges},
 pages = {150--160},
 volume = {11043},
 publisher = {Springer},
 isbn = {978-3-030-01363-9},
 series = {Lecture Notes in Computer Science},
 editor = {Stoyanov, Danail and Taylor, Zeike and Balocco, Simone and Sznitman, Raphael},
 booktitle = {Intravascular imaging and computer assisted stenting and large-scale annotation of biomedical data and expert label synthesis},
 year = {2018},
 address = {Cham},
 doi = {10.1007/978-3-030-01364-617}
}


@article{Ju.2018,
author = {Ju, Cheng and Bibaut, Aur{\'e}lien and {van der Laan}, Mark},
 year = {2018},
 title = {The Relative Performance of Ensemble Methods with Deep Convolutional Neural Networks for Image Classification},
 pages = {2800--2818},
 volume = {45},
 number = {15},
 issn = {0266-4763},
 journal = {Journal of applied statistics},
 doi = {10.1080/02664763.2018.1441383},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/31631918},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6800663}
}


@inproceedings{Kesim.2019,
 author = {Kesim, Ege and Dokur, Zumray and Olmez, Tamer},
 title = {X-Ray Chest Image Classification by A Small-Sized Convolutional Neural Network},
 pages = {1--5},
 publisher = {IEEE},
 isbn = {978-1-7281-1013-4},
 editor = {IEEE},
 booktitle = {2019 Scientific Meeting on Electrical-Electronics {\&} Biomedical Engineering and Computer Science (EBBT)},
 year = {2019},
 doi = {10.1109/EBBT.2019.8742050},
 file = {https://ieeexplore.ieee.org/document/8742050/}
}


@inproceedings{Kieffer.2017,
 author = {Kieffer, Brady and Babaie, Morteza and Kalra, Shivam and Tizhoosh, H. R.},
 title = {Convolutional neural networks for histopathology image classification: Training vs. Using pre-trained networks},
 pages = {1--6},
 publisher = {IEEE},
 isbn = {978-1-5386-1842-4},
 booktitle = {Proceedings of the Seventh International Conference on Image Processing Theory, Tools and Applications - IPTA 2017},
 year = {2017},
 address = {Piscataway, NJ},
 doi = {10.1109/IPTA.2017.8310149},
 file = {http://ieeexplore.ieee.org/document/8310149/}
}


@inproceedings{Kim.2017,
 author = {Kim, Pyong-Kun and Lim, Kil-Taek},
 title = {Vehicle Type Classification Using Bagging and Convolutional Neural Network on Multi View Surveillance Image},
 pages = {914--919},
 publisher = {IEEE},
 isbn = {978-1-5386-0733-6},
 editor = {IEEE},
 booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
 year = {2017},
 doi = {10.1109/CVPRW.2017.126},
 file = {http://ieeexplore.ieee.org/document/8014860/}
}


@article{Kolesnikov.2019,
 author = {Kolesnikov, Alexander I. and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
 year = {2019},
 title = {Large Scale Learning of General Visual Representations for Transfer},
 volume = {abs/1912.11370},
 journal = {ArXiv}
}


@inproceedings{Kortylewski.2020,
 author = {Kortylewski, Adam and Liu, Qing and Wang, Huiyu and Zhang, Zhishuai and Yuille, Alan},
 title = {Combining Compositional Models and Deep Networks For Robust Object Classification under Occlusion},
 editor = {IEEE},
 booktitle = {The IEEE Winter Conference on Applications of Computer Vision (WACV)},
 year = {2020}
}


@incollection{Kosiorek.2019,
 author = {Kosiorek, Adam and Sabour, Sara and Teh, Yee Whye and Hinton, Geoffrey E.},
 title = {Stacked Capsule Autoencoders},
 url = {http://papers.nips.cc/paper/9684-stacked-capsule-autoencoders.pdf},
 pages = {15512--15522},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@inproceedings{Kowsari.2018,
 author = {Kowsari, Kamran and Heidarysafa, Mojtaba and Brown, Donald E. and Meimandi, Kiana Jafari and Barnes, Laura E.},
 title = {RMDL},
 pages = {19--28},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450363549},
 series = {ICPS},
 editor = {{Association for Computing Machinery}},
 booktitle = {ICISDM 2018 2nd International Conference on Information System and Data Mining : Florida Polytechnic University, Florida, USA, April 9-11, 2018},
 year = {2018},
 address = {New York, New York},
 doi = {10.1145/3206098.3206111},
 file = {http://dl.acm.org/citation.cfm?doid=3206098}
}


@incollection{Krizhevsky.2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
 pages = {1097--1105},
 publisher = {{Curran Associates, Inc}},
 editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
 booktitle = {Advances in Neural Information Processing Systems 25},
 year = {2012}
}


@article{Krizhevsky.2017,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
 year = {2017},
 title = {ImageNet classification with deep convolutional neural networks},
 pages = {84--90},
 volume = {60},
 number = {6},
 issn = {00010782},
 journal = {Communications of the ACM},
 doi = {10.1145/3065386}
}


@incollection{Kubilius.2019,
 author = {Kubilius, Jonas and Schrimpf, Martin and Kar, Kohitij and Rajalingham, Rishi and Hong, Ha and Majaj, Najib and Issa, Elias and Bashivan, Pouya and Prescott-Roy, Jonathan and Schmidt, Kailyn and Nayebi, Aran and Bear, Daniel and Yamins, Daniel L. and DiCarlo, James J.},
 title = {Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs},
 url = {http://papers.nips.cc/paper/9441-brain-like-object-recognition-with-high-performing-shallow-recurrent-anns.pdf},
 pages = {12805--12816},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@inproceedings{Kyrkou.2019,
 author = {Kyrkou, Christos and Theocharides, Theocharis},
 title = {Deep-Learning-Based Aerial Image Classification for Emergency Response Applications Using Unmanned Aerial Vehicles},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
 year = {2019}
}


@inproceedings{Law.2017,
 author = {Law, Stephen and Shen, Yao and Seresinhe, Chanuki},
 title = {An application of convolutional neural network in street image classification},
 pages = {5--9},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450354981},
 editor = {Mao, Huina and Hu, Yingjie and Kar, Bandan and Gao, Song and McKenzie, Grant},
 booktitle = {Proceedings of the 1st Workshop on GeoAI},
 year = {2017},
 address = {New York, New York},
 doi = {10.1145/3149808.3149810},
 file = {http://dl.acm.org/citation.cfm?doid=3149808}
}


@proceedings{Lazaar.2019,
 year = {2019},
 title = {Proceedings of the 4th International Conference on Big Data and Internet of Things},
 address = {New York, NY, USA},
 publisher = {ACM},
 isbn = {9781450372404},
 editor = {Lazaar, Mohamed and Duvallet, Claude and {Al Achhab}, Mohammed and Mahboub, Oussama and Silkan, Hassan},
 doi = {10.1145/3372938},
 file = {http://dl.acm.org/doi/proceedings/10.1145/3372938}
}


@book{LealTaixe.2019,
 year = {2019},
 title = {Computer vision - ECCV 2018 workshops: Munich, Germany, September 8-14, 2018 : proceedings},
 keywords = {Deep learning;Robotik},
 address = {Cham},
 volume = {11134},
 publisher = {Springer},
 isbn = {978-3-030-11023-9},
 series = {Lecture Notes in Computer Science},
 editor = {Leal-Taix{\'e}, Laura and Roth, Stefan},
 doi = {10.1007/978-3-030-11024-6},
 file = {http://www.gbv.de/dms/tib-ub-hannover/1048781852.pdf}
}


@article{LeCun.1998,
 author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
 year = {1998},
 title = {Gradient-based learning applied to document recognition},
 pages = {2278--2324},
 volume = {86},
 number = {11},
 issn = {00189219},
 journal = {Proceedings of the IEEE},
 doi = {10.1109/5.726791}
}


@article{LeCun.2015,
 abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
 author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
 year = {2015},
 title = {Deep learning},
 pages = {436--444},
 volume = {521},
 number = {7553},
 journal = {Nature},
 doi = {10.1038/nature14539},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/26017442}
}


@article{LeHou.2015,
 author = {{Le Hou} and Samaras, Dimitris and Kur{\c{c}}, Tahsin M. and Gao, Yi and Davis, James E. and Saltz, Joel H.},
 year = {2015},
 title = {Patch-based Convolutional Neural Network for Whole Slide Tissue Image Classification},
 url = {http://arxiv.org/pdf/1504.07947.pdf},
 volume = {abs/1504.07947},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1504.07947}
}


@book{Leibe.2016,
 year = {2016},
 title = {Computer vision - ECCV 2016: 14th European conference, Amsterdam, The Netherlands, October 11-14, 2016 : proceedings},
 address = {Cham},
 volume = {9908},
 publisher = {Springer},
 isbn = {978-3-319-46492-3},
 series = {Lecture Notes in Computer Science},
 editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
 doi = {10.1007/978-3-319-46493-0},
 file = {http://www.gbv.de/dms/tib-ub-hannover/869723944.pdf}
}


@book{Leibe.2016b,
 year = {2016},
 title = {Computer Vision -- ECCV 2016},
 address = {Cham},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-319-46477-0},
 series = {Lecture Notes in Computer Science},
 editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
 doi = {10.1007/978-3-319-46478-7}
}


@incollection{Lenssen.2018,
 author = {Lenssen, Jan Eric and Fey, Matthias and Libuschewski, Pascal},
 title = {Group Equivariant Capsule Networks},
 url = {http://papers.nips.cc/paper/8100-group-equivariant-capsule-networks.pdf},
 pages = {8844--8853},
 publisher = {{Curran Associates, Inc}},
 editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 31},
 year = {2018}
}


@inproceedings{Leroux.2018,
 author = {Leroux, Sam and Molchanov, Pavlo and Simoens, Pieter and Dhoedt, Bart and Breuel, Thomas and Kautz, Jan},
 title = {IamNN: Iterative and Adaptive Mobile Neural Network for efficient  image classification},
 url = {https://arxiv.org/abs/1804.10123},
 publisher = {OpenReview.net},
 editor = {ICLR},
 booktitle = {6th International Conference on Learning Representations, ICLR 2018,  Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
 year = {2018}
}


@inproceedings{Levi.2015,
 author = {Levi, Gil and Hassncer, Tal},
 title = {Age and gender classification using convolutional neural networks},
 pages = {34--42},
 publisher = {IEEE},
 isbn = {978-1-4673-6759-2},
 editor = {IEEE},
 booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition workshops (CVPRW)},
 year = {2015},
 address = {Piscataway, NJ},
 doi = {10.1109/CVPRW.2015.7301352},
 file = {http://ieeexplore.ieee.org/document/7301352/}
}


@inproceedings{Li.2018,
 author = {Li, Bin and Ge, Yunhao and Zhao, Yanzheng and Guan, Enguang and {Yan Weixin}},
 title = {Benign and malignant mammographic image classification based on Convolutional Neural Networks},
 pages = {247--251},
 publisher = {{The Association for Computing Machinery}},
 isbn = {978-1-4503-6353-2},
 series = {ICPS},
 editor = {ACM},
 booktitle = {Proceedings of 2018 10th International Conference on Machine Learning and Computing (ICMLC 2018)},
 year = {2018},
 address = {New York, New York, USA}
}


@inproceedings{Lian.2018,
 author = {Lian, Chunyan and Liang, Yixiong and Kang, Rui and Xiang, Yao},
 title = {Deep Convolutional Neural Networks for Diabetic Ret\-i\-nop\-a\-thy Classification},
 pages = {68--72},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450364607},
 series = {ICPS},
 editor = {ACM},
 booktitle = {ICAIP 2018},
 year = {2018},
 address = {New York, New York},
 doi = {10.1145/3239576.3239589},
 file = {http://dl.acm.org/citation.cfm?doid=3239576}
}


@article{Liang.2018,
 author = {Liang, Senwei and Khoo, Yuehaw and Yang, Haizhao},
 year = {2018},
 title = {Drop-Activation: Implicit Parameter Reduction and Harmonic Regularization},
 url = {http://arxiv.org/abs/1811.05850},
 volume = {abs/1811.05850},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1811.05850}
}


@incollection{Lim.2019,
 author = {Lim, Sungbin and Kim, Ildoo and Kim, Taesup and Kim, Chiheon and Kim, Sungwoong},
 title = {Fast AutoAugment},
 url = {http://papers.nips.cc/paper/8892-fast-autoaugment.pdf},
 pages = {6665--6675},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@article{Lin.2013,
 author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
 year = {2013},
 title = {Network In Network},
 url = {https://arxiv.org/abs/1312.4400},
 volume = {abs/1312.4400},
 journal = {CoRR}
}


@inproceedings{Liu.2015,
 author = {Liu, Baoyuan and Wang, Min and Foroosh, Hassan and Tappen, Marshall and Pensky, Marianna},
 title = {Sparse Convolutional Neural Networks},
 editor = {IEEE},
 booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 year = {2015}
}


@inproceedings{Liu.2016,
 author = {Liu, Jiang and Gao, Chenqiang and Meng, Deyu and Zuo, Wangmeng},
 title = {Two-Stream Contextualized CNN for Fine-Grained Image Classification},
 url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewPaper/11772},
 pages = {4232-3233},
 editor = {{AAAI Press}},
 booktitle = {Thirtieth AAAI Conference on Artificial Intelligence},
 year = {2016}
}


@incollection{Liu.2018,
 author = {Liu, Chenxi and Zoph, Barret and Neumann, Maxim and Shlens, Jonathon and Hua, Wei and Li, Li-Jia and Fei-Fei, Li and Yuille, Alan and Huang, Jonathan and Murphy, Kevin},
 title = {Progressive Neural Architecture Search},
 pages = {19--35},
 volume = {11205},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-030-01245-8},
 series = {Image Processing, Computer Vision, Pattern Recognition, and Graphics},
 editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
 booktitle = {Computer Vision - ECCV 2018},
 year = {2018},
 address = {Cham},
 doi = {10.1007/978-3-030-01246-52}
}


@article{Liu.2020,
 author = {Liu, Qun and Basu, Saikat and Ganguly, Sangram and Mukhopadhyay, Supratik and DiBiano, Robert and Karki, Manohar and Nemani, Ramakrishna},
 year = {2020},
 title = {DeepSat V2: feature augmented convolutional neural nets for satellite image classification},
 pages = {156--165},
 volume = {11},
 number = {2},
 issn = {2150-704X},
 journal = {Remote Sensing Letters},
 doi = {10.1080/2150704X.2019.1693071}
}


@incollection{Lu.2019,
 author = {Lu, Alex and Lu, Amy and Schormann, Wiebke and Ghassemi, Marzyeh and Andrews, David and Moses, Alan},
 title = {The Cells Out of Sample (COOS) dataset and benchmarks for measuring out-of-sample generalization of image classifiers},
 url = {http://papers.nips.cc/paper/8461-the-cells-out-of-sample-coos-dataset-and-benchmarks-for-measuring-out-of-sample-generalization-of-image-classifiers.pdf},
 pages = {1854--1862},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@article{Madrazo.2019,
 author = {Madrazo, Celia Fern{\'a}ndez and Heredia, Ignacio and Lloret, Lara and {Marco de Lucas}, Jes{\'u}s},
 year = {2019},
 title = {Application of a Convolutional Neural Network for image classification for the analysis of collisions in High Energy Physics},
 pages = {06017},
 volume = {214},
 journal = {EPJ Web of Conferences},
 doi = {10.1051/epjconf/201921406017}
}


@incollection{Mahajan.2018,
 author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and {van der Maaten}, Laurens},
 title = {Exploring the Limits of Weakly Supervised Pretraining},
 pages = {185--201},
 volume = {11206},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-030-01215-1},
 series = {Image Processing, Computer Vision, Pattern Recognition, and Graphics},
 editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
 booktitle = {Computer Vision - ECCV 2018},
 year = {2018},
 address = {Cham},
 doi = {10.1007/978-3-030-01216-812}
}


@article{Makinen.2008,
 abstract = {We present a systematic study on gender classification with automatically detected and aligned faces. We experimented with 120 combinations of automatic face detection, face alignment and gender classification. One of the findings was that the automatic face alignment methods did not increase the gender classification rates. However, manual alignment increased classification rates a little, which suggests that automatic alignment would be useful when the alignment methods are further improved. We also found that the gender classification methods performed almost equally well with different input image sizes. In any case, the best classification rate was achieved with a support vector machine. A neural network and Adaboost achieved almost as good classification rates as the support vector machine and could be used in applications where classification speed is considered more important than the best possible classification accuracy.},
 author = {M{\"a}kinen, Erno and Raisamo, Roope},
 year = {2008},
 title = {Evaluation of gender classification methods with automatically detected and aligned faces},
 keywords = {Algorithms;Artificial intelligence;Biometry/methods;Face/anatomy {\&} histology/physiology;Humans;Image Enhancement/methods;Image Interpretation, Computer-Assisted/methods;Information Storage and Retrieval/methods;Pattern Recognition, Automated/methods;Reproducibility of Results;Sensitivity and Specificity;Sex Characteristics;Sex Determination Analysis/methods;Sex Factors;Subtraction Technique},
 pages = {541--547},
 volume = {30},
 number = {3},
 journal = {IEEE transactions on pattern analysis and machine intelligence},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/18195447}
}


@proceedings{Mao.2017,
 year = {2017},
 title = {Proceedings of the 1st Workshop on GeoAI: AI and Deep Learning for Geographic Knowledge Discovery : 2017, Los Angeles Area, CA, USA : GeoAI'17},
 keywords = {Data mining;Geospatial data;Machine learning},
 address = {New York, New York},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450354981},
 editor = {Mao, Huina and Hu, Yingjie and Kar, Bandan and Gao, Song and McKenzie, Grant},
 institution = {{ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems}},
 doi = {10.1145/3149808},
 file = {http://www.worldcat.org/oclc/1035794472}
}


@article{Matsunaga.2017,
 author = {Matsunaga, Kazuhisa and Hamada, Akira and Minagawa, Akane and Koga, Hiroshi},
 year = {2017},
 title = {Image Classification of Melanoma, Nevus and Seborrheic Keratosis by  Deep Neural Network Ensemble},
 url = {http://arxiv.org/pdf/1703.03108v1},
 volume = {abs/1703.03108},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1703.03108}
}


@article{McDonnell.2015,
 author = {McDonnell, Mark D. and Vladusich, Tony},
 year = {2015},
 title = {Enhanced Image Classification With a Fast-Learning Shallow Convolutional  Neural Network},
 url = {http://arxiv.org/pdf/1503.04596v3},
 volume = {abs/1503.04596},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1503.04596}
}


@misc{Mehdi.2019,
 author = {Mehdi, Yousefzadeh and Hossein, Motahari},
 year = {2019},
 title = {Skin Lesion Analysis Towards Melanoma Detection Using Softmax Ensemble Model and Sigmoid Ensemble Model},
 url = {https://isic-challenge-stade.s3.amazonaws.com/49ebcaba-ce4c-4e26-97aa-895ee6409ef7/ISIC.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=Uoq2LKsQoQn67Qm5iHdlNMThEqM%3D&Expires=1584572948}
}


@article{Mendes.2018,
 author = {Mendes, Danilo Barros and Silva, Nilton Correia da},
 year = {2018},
 title = {Skin Lesions Classification Using Convolutional Neural Networks in  Clinical Images},
 volume = {abs/1812.02316},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1812.02316}
}


@book{Mitrovic.2018,
 abstract = {This book constitutes the proceedings of the 31st Australasian Joint Conference on Artificial Intelligence, AI 2018, held in Wellington, New Zealand, in December 2018. The 50 full and 26 short papers presented in this volume were carefully reviewed and selected from 125 submissions. The paper were organized in topical sections named: agents, games and robotics; AI applications and innovations; computer vision; constraints and search; evolutionary computation; knowledge representation and reasoning; machine learning and data mining; planning and scheduling; and text mining and NLP},
 year = {2018},
 title = {AI 2018: Advances in Artificial Intelligence: 31st Australasian Joint Conference, Wellington, New Zealand, December 11-14, 2018, Proceedings},
 keywords = {Artificial intelligence;Computer science;Computer software;Computer vision;Software engineering},
 address = {Cham},
 volume = {11320},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-030-03990-5},
 series = {Lecture Notes in Artificial Intelligence},
 editor = {Mitrovic, Tanja and Xue, Bing and Li, Xiaodong},
 doi = {10.1007/978-3-030-03991-2}
}


@inproceedings{Murthy.2016,
 author = {Murthy, Venkatesh N. and Singh, Vivek and Chen, Terrence and Manmatha, R. and Comaniciu, Dorin},
 title = {Deep Decision Network for Multi-Class Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2016}
}


@incollection{Nazeri.2018,
 author = {Nazeri, Kamyar and Aminpour, Azad and Ebrahimi, Mehran},
 title = {Two-Stage Convolutional Neural Network for Breast Cancer Histology Image Classification},
 publisher = {Springer},
 isbn = {978-3-319-92999-6},
 series = {Lecture Notes in Computer Science},
 editor = {Campilho, Aur{\'e}lio and Karray, Fakhri and {Haar Romeny}, Bart M. ter},
 booktitle = {Image analysis and recognition15th international conference, ICIAR 2018, P{\'o}voa de Varzim, Portugal, June 27-29, 2018 : proceedings},
 year = {2018},
 address = {Cham}
}


@inproceedings{Nejad.2017,
 author = {Nejad, Elaheh Mahraban and Affendey, Lilly Suriani and Latip, Rohaya Binti and {Bin Ishak}, Iskandar},
 title = {Classification of Histopathology Images of Breast into Benign and Malignant using a Single-layer Convolutional Neural Network},
 pages = {50--53},
 publisher = {ACM},
 isbn = {9781450352895},
 editor = {ACM},
 booktitle = {Proceedings of the International Conference on Imaging, Signal Processing and Communication},
 year = {2017},
 address = {[Place of publication not identified]},
 doi = {10.1145/3132300.3132331},
 file = {http://dl.acm.org/citation.cfm?doid=3132300}
}


@proceedings{Nguyen.2017,
 year = {2017},
 title = {KSE 2017: 2017 9th International Conference on Knowledge and Systems Engineering (KSE), October 19-21, 2017, Hue, Vietnam : proceedings},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5386-3576-6},
 editor = {Nguyen, Thanh-Thuy},
 institution = {{International Conference on Knowledge and Systems Engineering} and KSE}
}


@article{Nkland.2019,
 author = {N{\o}kland, Arild and Eidnes, Lars Hiller},
 year = {2019},
 title = {Training Neural Networks with Local Error Signals},
 url = {https://arxiv.org/abs/1901.06656v2},
 volume = {abs/1901.06656},
 journal = {ArXiv}
}


@article{Nogueira.2017,
 author = {Nogueira, Keiller and Penatti, Ot{\'a}vio A.B. and {dos Santos}, Jefersson A.},
 year = {2017},
 title = {Towards better exploiting convolutional neural networks for remote sensing scene classification},
 pages = {539--556},
 volume = {61},
 issn = {00313203},
 journal = {Pattern Recognition},
 doi = {10.1016/j.patcog.2016.07.001}
}


@incollection{Orhan.2018,
 author = {Orhan, Emin},
 title = {A Simple Cache Model for Image Recognition},
 url = {http://papers.nips.cc/paper/8214-a-simple-cache-model-for-image-recognition.pdf},
 pages = {10107--10116},
 publisher = {{Curran Associates, Inc}},
 editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 31},
 year = {2018}
}


@misc{Pachecoa.2019,
 author = {Pachecoa, Andre G. C. and Alib, Abder-Rahman and Trappenberg, Thomas},
 year = {2019},
 title = {Skin cancer detection based on deep learning andentropy to detect outlier samples},
 url = {https://isic-challenge-stade.s3.amazonaws.com/f6d46ceb-bf66-42ff-8b22-49562aefd4b8/ISIC_2019.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=RSn7Cy%2FfypDhWIRhDWhOJr028Lk%3D&Expires=1584572948}
}


@inproceedings{Peng.2018,
 author = {Peng, Binbin and Chen, Lin and Shang, Mingsheng and Xu, Jianjun},
 title = {Fully Convolutional Neural Networks for Tissue Histopathology Image Classification and Segmentation},
 pages = {1403--1407},
 publisher = {IEEE},
 isbn = {978-1-4799-7061-2},
 booktitle = {2018 IEEE International Conference on Image Processing},
 year = {2018},
 address = {Piscataway, NJ},
 doi = {10.1109/ICIP.2018.8451517},
 file = {https://ieeexplore.ieee.org/document/8451517/}
}


@book{Pereira.2012,
 year = {2012},
 title = {Advances in Neural Information Processing Systems 25},
 publisher = {{Curran Associates, Inc}},
 editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.}
}


@inproceedings{Perez.2019,
 author = {Perez, Fabio and Avila, Sandra and Valle, Eduardo},
 title = {Solo or Ensemble? Choosing a CNN Architecture for Melanoma Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
 year = {2019}
}


@inproceedings{Phan.2020,
 author = {Phan, Hai and Huynh, Dang The and He, Yihui and Savvides, Marios and Shen, Zhiqiang},
 title = {MoBiNet: A Mobile Binary Network for Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE Winter Conference on Applications of Computer Vision (WACV)},
 year = {2020}
}


@incollection{Pimkin.2018,
 author = {Pimkin, Artem and Makarchuk, Gleb and Kondratenko, Vladimir and Pisov, Maxim and Krivov, Egor and Belyaev, Mikhail},
 title = {Ensembling Neural Networks for Digital Pathology Images Classification and Segmentation},
 pages = {877--886},
 volume = {10882},
 publisher = {Springer},
 isbn = {978-3-319-92999-6},
 series = {Lecture Notes in Computer Science},
 editor = {Campilho, Aur{\'e}lio and Karray, Fakhri and {Haar Romeny}, Bart M. ter},
 booktitle = {Image analysis and recognition15th international conference, ICIAR 2018, P{\'o}voa de Varzim, Portugal, June 27-29, 2018 : proceedings},
 year = {2018},
 address = {Cham},
 doi = {10.1007/978-3-319-93000-8100}
}


@misc{Pollastri.2019,
 author = {Pollastri, Federico and Juan, Maro{\~n}as and Parre{\~n}o, Mario and Bolelli, Federico and Paredes, Roberto and Grana, Costantino and Albiol, Alberto},
 year = {2019},
 title = {AImageLab-PRHLT at ISIC Challenge 2019},
 url = {https://isic-challenge-stade.s3.amazonaws.com/345cf261-bc0d-4e8c-b0f4-fa6d6fda16d2/2019_ISIC_Challenge_UNIMORE_UPV.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=z4g8hhS%2BSKTMFsES4b5EMFE6Qz8%3D&Expires=1584572948}
}


@inproceedings{Ponti.2017,
 author = {Ponti, Moacir Antonelli and Ribeiro, Leonardo Sampaio Ferraz and Nazare, Tiago Santana and Bui, Tu and Collomosse, John},
 title = {Everything You Wanted to Know about Deep Learning for Computer Vision but Were Afraid to Ask},
 pages = {17--41},
 publisher = {IEEE},
 isbn = {978-1-5386-0619-3},
 booktitle = {SIBGRAPI-T 2017},
 year = {2017},
 address = {Piscataway, NJ},
 doi = {10.1109/SIBGRAPI-T.2017.12},
 file = {http://ieeexplore.ieee.org/document/8250222/}
}


@incollection{Rastegari.2016,
 author = {Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
 title = {XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks},
 pages = {525--542},
 volume = {9908},
 publisher = {Springer},
 isbn = {978-3-319-46492-3},
 series = {Lecture Notes in Computer Science},
 editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
 booktitle = {Computer vision - ECCV 2016},
 year = {2016},
 address = {Cham},
 doi = {10.1007/978-3-319-46493-032}
}


@article{Rawat.2017,
 abstract = {Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges.},
 author = {Rawat, Waseem and Wang, Zenghui},
 year = {2017},
 title = {Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review},
 pages = {2352--2449},
 volume = {29},
 number = {9},
 journal = {Neural computation},
 doi = {10.1162/NECOa00990},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28599112}
}


@article{Real.2019,
 author = {Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V.},
 year = {2019},
 title = {Regularized Evolution for Image Classifier Architecture Search},
 pages = {4780--4789},
 volume = {33},
 issn = {2159-5399},
 journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
 doi = {10.1609/aaai.v33i01.33014780}
}


@inproceedings{Roth.2015,
 author = {Roth, Holger R. and Lee, Christopher T. and Shin, Hoo-Chang and Seff, Ari and Kim, Lauren and Yao, Jianhua and Lu, Le and Summers, Ronald M.},
 title = {Anatomy-specific classification of medical images using deep convolutional nets},
 pages = {101--104},
 publisher = {IEEE},
 isbn = {978-1-4799-2374-8},
 booktitle = {2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)},
 year = {2015},
 address = {Piscataway, NJ},
 doi = {10.1109/ISBI.2015.7163826},
 file = {http://ieeexplore.ieee.org/document/7163826/}
}


@incollection{Sabour.2017,
 author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E.},
 title = {Dynamic Routing Between Capsules},
 url = {http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf},
 pages = {3856--3866},
 publisher = {{Curran Associates, Inc}},
 editor = {{I. Guyon} and {U. V. Luxburg} and {S. Bengio} and {H. Wallach} and {R. Fergus} and {S. Vishwanathan} and {R. Garnett}},
 booktitle = {Advances in Neural Information Processing Systems 30},
 year = {2017}
}


@article{Sato.2015,
 author = {Sato, Ikuro and Nishimura, Hiroki and Yokoi, Kensuke},
 year = {2015},
 title = {APAC: Augmented PAttern Classification with Neural Networks},
 url = {http://arxiv.org/abs/1505.03229},
 volume = {abs/1505.03229},
 journal = {CoRR}
}


@article{Sosnovik.2020,
	author = {Sosnovik, Ivan and Szmaja, Micha{\l} and Smeulders, Arnold},
	year = {2020},
	title = {Scale-Equivariant Steerable Networks},
	url = {https://openreview.net/pdf?id=HJgpugrKPS},
	journal = {ICLR 2020}
}


@inproceedings{Seo.2018,
 author = {Seo, Yian and Shin, Kyung-shik},
 title = {Image classification of fine-grained fashion image based on style using pre-trained convolutional neural network},
 pages = {387--390},
 publisher = {IEEE},
 isbn = {978-1-5386-4794-3},
 booktitle = {2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA 2018)},
 year = {2018},
 address = {Piscataway, NJ},
 doi = {10.1109/ICBDA.2018.8367713},
 file = {https://ieeexplore.ieee.org/document/8367713/}
}


@inproceedings{Shen.2016,
 author = {Shen, Xu and Tian, Xinmei and He, Anfeng and Sun, Shaoyan and Tao, Dacheng},
 title = {Transform-Invariant Convolutional Neural Networks for Image Classification and Search},
 pages = {1345--1354},
 publisher = {{ACM Association for Computing Machinery}},
 isbn = {9781450336031},
 editor = {Hanjalic, Alan and Snoek, Cees and Worring, Marcel and Bulterman, Dick and Huet, Benoit and Kelliher, Aisling and Kompatsiaris, Yiannis and Li, Jin},
 booktitle = {MM'16 Proceedings of the 2016 ACM Multimedia Conference : October 15-19, 2016, Amsterdam, The Netherlands},
 year = {2016},
 address = {New York, NY},
 doi = {10.1145/2964284.2964316},
 file = {http://dl.acm.org/citation.cfm?doid=2964284}
}


@article{Shetty.2016,
 author = {Shetty, Suyash},
 year = {2016},
 title = {Application of Convolutional Neural Network for Image Classification  on Pascal VOC Challenge 2012 dataset},
 url = {https://arxiv.org/pdf/1607.03785.pdf},
 volume = {abs/1607.03785},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1607.03785}
}


@article{Shi.2019,
 abstract = {We develop a fine-grained image classifier using a general deep convolutional neural network (DCNN). We improve the fine-grained image classification accuracy of a DCNN model from the following two aspects. First, to better model the h -level hierarchical label structure of the fine-grained image classes contained in the given training data set, we introduce h fully connected (fc) layers to replace the top fc layer of a given DCNN model and train them with the cascaded softmax loss. Second, we propose a novel loss function, namely, generalized large-margin (GLM) loss, to make the given DCNN model explicitly explore the hierarchical label structure and the similarity regularities of the fine-grained image classes. The GLM loss explicitly not only reduces between-class similarity and within-class variance of the learned features by DCNN models but also makes the subclasses belonging to the same coarse class be more similar to each other than those belonging to different coarse classes in the feature space. Moreover, the proposed fine-grained image classification framework is independent and can be applied to any DCNN structures. Comprehensive experimental evaluations of several general DCNN models (AlexNet, GoogLeNet, and VGG) using three benchmark data sets (Stanford car, fine-grained visual classification-aircraft, and CUB-200-2011) for the fine-grained image classification task demonstrate the effectiveness of our method.},
 author = {Shi, Weiwei and Gong, Yihong and Tao, Xiaoyu and Cheng and Zheng, Nanning},
 year = {2019},
 title = {Fine-Grained Image Classification Using Modified DCNNs Trained by Cascaded Softmax and Generalized Large-Margin Losses},
 pages = {683--694},
 volume = {30},
 number = {3},
 journal = {IEEE transactions on neural networks and learning systems},
 doi = {10.1109/TNNLS.2018.2852721},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/30047915}
}


@inproceedings{Shima.2018,
 author = {Shima, Yoshihiro and Omori, Yuki},
 title = {Image Augmentation for Classifying Facial Expression Images by Using Deep Neural Network Pre-trained with Object Image Database},
 pages = {140--146},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450365307},
 series = {ICPS},
 editor = {ACM},
 booktitle = {Proceedings of ICRCA 2018},
 year = {2018},
 address = {New York, New York},
 doi = {10.1145/3265639.3265664},
 file = {http://dl.acm.org/citation.cfm?doid=3265639}
}


@proceedings{SIBGRAPIConferenceonGraphicsPatternsandImages.2017,
 year = {2017},
 title = {SIBGRAPI-T 2017: 2017 30th SIBGRAPI Conference on Graphics, Patterns and Images Tutorials : Niter{\'o}i, Rio de Janeiro, Brazil, 17-20 October 2017 : proceedings},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-5386-0619-3},
 institution = {{SIBGRAPI Conference on Graphics, Patterns and Images} and {Universidade Federal Fluminense} and {Pontif{\'i}cia Universidade Cat{\'o}lica do Rio de Janeiro} and {Universidade Federal do Rio de Janeiro} and {Sociedade Brasileira de Computa{\c{c}}{\~a}o} and SIBGRAPI and {SIBGRAPI Conference on Graphics, Patterns and Images Tutorials} and SIBGRAPI-T}
}


@article{Simonyan.2014,
 author = {Simonyan, Karen and Zisserman, Andrew},
 year = {2014},
 title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
 url = {https://arxiv.org/abs/1409.1556},
 volume = {abs/1409.1556},
 journal = {CoRR}
}


@inproceedings{Singh.2018,
 author = {Singh, Bharat and Li, Hengduo and Sharma, Abhishek and Davis, Larry S.},
 title = {R-FCN-3000 at 30fps: Decoupling Detection and Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2018}
}


@article{Sladojevic.2016,
 abstract = {The latest generation of convolutional neural networks (CNNs) has achieved impressive results in the field of image classification. This paper is concerned with a new approach to the development of plant disease recognition model, based on leaf image classification, by the use of deep convolutional networks. Novel way of training and the methodology used facilitate a quick and easy system implementation in practice. The developed model is able to recognize 13 different types of plant diseases out of healthy leaves, with the ability to distinguish plant leaves from their surroundings. According to our knowledge, this method for plant disease recognition has been proposed for the first time. All essential steps required for implementing this disease recognition model are fully described throughout the paper, starting from gathering images in order to create a database, assessed by agricultural experts. Caffe, a deep learning framework developed by Berkley Vision and Learning Centre, was used to perform the deep CNN training. The experimental results on the developed model achieved precision between 91{\%} and 98{\%}, for separate class tests, on average 96.3{\%}.},
 author = {Sladojevic, Srdjan and Arsenovic, Marko and Anderla, Andras and Culibrk, Dubravko and Stefanovic, Darko},
 year = {2016},
 title = {Deep Neural Networks Based Recognition of Plant Diseases by Leaf Image Classification},
 pages = {3289801},
 volume = {2016},
 journal = {Computational intelligence and neuroscience},
 doi = {10.1155/2016/3289801},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/27418923},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4934169}
}


@inproceedings{Slavkovikj.2015,
 author = {Slavkovikj, Viktor and Verstockt, Steven and de Neve, Wesley and {van Hoecke}, Sofie and {van de Walle}, Rik},
 title = {Hyperspectral Image Classification with Convolutional Neural Networks},
 pages = {1159--1162},
 publisher = {{ACM Press}},
 isbn = {9781450334594},
 editor = {Zhou, Xiaofang and Smeaton, Alan F. and Tian, Qi and Bulterman, Dick C.A. and Shen, Heng Tao and Mayer-Patel, Ketan and Yan, Shuicheng},
 booktitle = {MM'15},
 year = {2015},
 address = {New York, New York, USA},
 doi = {10.1145/2733373.2806306},
 file = {http://dl.acm.org/citation.cfm?doid=2733373}
}


@incollection{Socher.2012,
 author = {Socher, Richard and Huval, Brody and Bath, Bharath and Manning, Christopher D. and Ng, Andrew Y.},
 title = {Convolutional-Recursive Deep Learning for 3D Object Classification},
 url = {http://papers.nips.cc/paper/4773-convolutional-recursive-deep-learning-for-3d-object-classification.pdf},
 pages = {656--664},
 publisher = {{Curran Associates, Inc}},
 editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
 booktitle = {Advances in Neural Information Processing Systems 25},
 year = {2012}
}


@inproceedings{Spanhol.2016,
 author = {Spanhol, Fabio Alexandre and Oliveira, Luiz S. and Petitjean, Caroline and Heutte, Laurent},
 title = {Breast cancer histopathological image classification using Convolutional Neural Networks},
 pages = {2560--2567},
 publisher = {IEEE},
 isbn = {978-1-5090-0620-5},
 editor = {IEEE},
 booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
 year = {2016},
 address = {Piscataway, NJ},
 doi = {10.1109/IJCNN.2016.7727519},
 file = {http://ieeexplore.ieee.org/document/7727519/}
}


@proceedings{Springer.2018,
 year = {2018},
 title = {The European Conference on Computer Vision (ECCV)},
 editor = {Springer}
}


@inproceedings{Stamoulis.2018,
 author = {Stamoulis, Dimitrios and Chin, Ting-Wu and Prakash, Anand Krishnan and Fang, Haocheng and Sajja, Sribhuvan and Bognar, Mitchell and Marculescu, Diana},
 title = {Designing Adaptive Neural Networks for Energy-Constrained Image Classification},
 pages = {1--8},
 publisher = {IEEE},
 isbn = {9781450359504},
 editor = {Bahar, Iris},
 booktitle = {2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
 year = {2018},
 address = {Piscataway, NJ},
 doi = {10.1145/3240765.3240796},
 file = {http://dl.acm.org/citation.cfm?doid=3240765}
}


@book{Stoyanov.2018,
 year = {2018},
 title = {Intravascular imaging and computer assisted stenting and large-scale annotation of biomedical data and expert label synthesis: 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018 : proceedings},
 price = {(Festeinband : circa EUR 85.60 (DE) (freier Preis), circa EUR 88.00 (AT) (freier Preis), circa CHF 88.00 (freier Preis))},
 address = {Cham},
 volume = {11043},
 publisher = {Springer},
 isbn = {978-3-030-01363-9},
 series = {Lecture Notes in Computer Science},
 editor = {Stoyanov, Danail and Taylor, Zeike and Balocco, Simone and Sznitman, Raphael},
 doi = {10.1007/978-3-030-01364-6},
 file = {http://deposit.dnb.de/cgi-bin/dokserv?id=d7a38668320b47ba85ef73930492c46b&prov=M&dok_var=1&dok_ext=htm},
 file = {http://vub.de/cover/data/isbn:9783030013639/medium/true/de/vub/cover.jpg}
}


@inproceedings{Su.2018,
 author = {Su, Dong and Zhang, Huan and Chen, Hongge and Yi, Jinfeng and Chen, Pin-Yu and Gao, Yupeng},
 title = {Is Robustness the Cost of Accuracy? -- A Comprehensive Study on the Robustness of 18 Deep Image Classification Models},
 editor = {Springer},
 booktitle = {The European Conference on Computer Vision (ECCV)},
 year = {2018}
}


@inproceedings{Sultana.2019,
 author = {Sultana, Farhana and Sufian, Abu and Dutta, Paramartha},
 title = {Advancements in Image Classification using Convolutional Neural Network},
 pages = {122--129},
 publisher = {IEEE},
 isbn = {978-1-5386-7638-7},
 editor = {Bhattacharyya, Siddhartha},
 booktitle = {Proceedings, 2018 Fourth IEEE International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)},
 year = {2019},
 address = {[Piscataway, New Jersey]},
 doi = {10.1109/ICRCICN.2018.8718718},
 file = {https://ieeexplore.ieee.org/document/8718718/}
}


@incollection{Sun.2016,
 author = {Sun, Zhun and Ozay, Mete and Okatani, Takayuki},
 title = {Design of Kernels in Convolutional Neural Networks for Image Classification},
 pages = {51--66},
 volume = {9911},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-319-46477-0},
 series = {Lecture Notes in Computer Science},
 editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
 booktitle = {Computer Vision -- ECCV 2016},
 year = {2016},
 address = {Cham},
 doi = {10.1007/978-3-319-46478-74}
}


@article{Sun.2019,
 author = {Sun, Yanan and Xue, Bing and Zhang, Mengjie and Yen, Gary G.},
 year = {2019},
 title = {Evolving Deep Convolutional Neural Networks for Image Classification},
 pages = {1},
 issn = {1089-778X},
 journal = {IEEE Transactions on Evolutionary Computation},
 doi = {10.1109/TEVC.2019.2916183}
}


@inproceedings{Szegedy.2015,
 author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
 title = {Going deeper with convolutions},
 pages = {1--9},
 publisher = {IEEE},
 isbn = {978-1-4673-6964-0},
 editor = {IEEE},
 booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2015},
 doi = {10.1109/CVPR.2015.7298594},
 file = {http://ieeexplore.ieee.org/document/7298594/}
}


@inproceedings{Szegedy.2017,
 author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A.},
 title = {Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning},
 pages = {4278--4284},
 publisher = {{AAAI Press}},
 series = {AAAI'17},
 editor = {{AAAI Press}},
 booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
 year = {2017}
}


@inproceedings{Taha.2020,
 author = {Taha, Ahmed and Chen, Yi-Ting and Misu, Teruhisa and Shrivastava, Abhinav and Davis, Larry},
 title = {Boosting Standard Classification Architectures Through a Ranking Regularizer},
 editor = {IEEE},
 booktitle = {The IEEE Winter Conference on Applications of Computer Vision (WACV)},
 year = {2020}
}


@inproceedings{Tan.2019,
 author = {Tan, Mingxing and {Le V}, Quoc},
 title = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
 url = {https://arxiv.org/pdf/1905.11946v3.pdf},
 editor = {ICML},
 booktitle = {2019 International Conference on Machine Learning (ICML)},
 year = {2019}
}


@article{Tensmeyer.2017,
 author = {Tensmeyer, Chris and Martinez, Tony},
 year = {2017},
 title = {Analysis of Convolutional Neural Networks for Document Image Classification},
 volume = {abs/1708.03273},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1708.03273}
}


@article{Teramoto.2017,
 abstract = {Lung cancer is a leading cause of death worldwide. Currently, in differential diagnosis of lung cancer, accurate classification of cancer types (adenocarcinoma, squamous cell carcinoma, and small cell carcinoma) is required. However, improving the accuracy and stability of diagnosis is challenging. In this study, we developed an automated classification scheme for lung cancers presented in microscopic images using a deep convolutional neural network (DCNN), which is a major deep learning technique. The DCNN used for classification consists of three convolutional layers, three pooling layers, and two fully connected layers. In evaluation experiments conducted, the DCNN was trained using our original database with a graphics processing unit. Microscopic images were first cropped and resampled to obtain images with resolution of 256 $\times$ 256 pixels and, to prevent overfitting, collected images were augmented via rotation, flipping, and filtering. The probabilities of three types of cancers were estimated using the developed scheme and its classification accuracy was evaluated using threefold cross validation. In the results obtained, approximately 71{\%} of the images were classified correctly, which is on par with the accuracy of cytotechnologists and pathologists. Thus, the developed scheme is useful for classification of lung cancers from microscopic images.},
 author = {Teramoto, Atsushi and Tsukamoto, Tetsuya and Kiriyama, Yuka and Fujita, Hiroshi},
 year = {2017},
 title = {Automated Classification of Lung Cancer Types from Cytological Images Using Deep Convolutional Neural Networks},
 volume = {2017},
 journal = {BioMed research international},
 doi = {10.1155/2017/4067832},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28884120},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5572620}
}


@proceedings{Thang.2015,
 year = {2015},
 title = {SoICT 2015: Proceedings of the Fifth Symposium on Information and Communication Technology : Hue, Vietnam, December 3-4, 2015},
 keywords = {Communication and technology;Information technology;Telecommunication},
 address = {New York, New York},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450338431},
 series = {ICPS},
 editor = {Thang, Huynh Quyet and Phuong, Le Anh and de Raedt, Luc and Deville, Yves and Bui, Marc and Linh, Truong Thi Dieu and Oanh, Nguyen Thi and Sang, Dinh Viet and Ngoc, Nguyen Ba},
 doi = {10.1145/2833258},
 file = {http://www.worldcat.org/oclc/962029619}
}


@inproceedings{Tokozume.2018,
 author = {Tokozume, Yuji and Ushiku, Yoshitaka and Harada, Tatsuya},
 title = {Between-Class Learning for Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2018}
}


@inproceedings{Too.2019,
 author = {Too, Edna C. and Li, Yujian and Njuki, Sam and Yamak, Peter T. and Zhang, Ting},
 title = {The Convolution Neural Network with Transformed Exponential Linear Unit Activation Function for Image Classification},
 pages = {55--62},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450361750},
 series = {ICPS},
 editor = {ACM},
 booktitle = {IVSP 2019},
 year = {2019},
 address = {New York, New York},
 doi = {10.1145/3317640.3317649},
 file = {http://dl.acm.org/citation.cfm?doid=3317640}
}


@incollection{Touvron.2019,
 author = {Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and Jegou, Herve},
 title = {Fixing the train-test resolution discrepancy},
 url = {http://papers.nips.cc/paper/9035-fixing-the-train-test-resolution-discrepancy.pdf},
 pages = {8252--8262},
 publisher = {{Curran Associates, Inc}},
 editor = {{H. Wallach} and {H. Larochelle} and {A. Beygelzimer} and {F. d$\backslash$textquotesingle Alch{\'e}-Buc} and {E. Fox} and {R. Garnett}},
 booktitle = {Advances in Neural Information Processing Systems 32},
 year = {2019}
}


@inproceedings{Tyas.2017,
 author = {Tyas, Dyah Aruming and Ratnaningsih, Tri and Harjoko, Agus and Hartati, Sri},
 title = {The Classification of Abnormal Red Blood Cell on The Minor Thalassemia Case Using Artificial Neural Network and Convolutional Neural Network},
 pages = {228--233},
 publisher = {ACM},
 isbn = {9781450353830},
 editor = {ACM},
 booktitle = {Proceedings of the International Conference on Video and Image Processing},
 year = {2017},
 address = {[Place of publication not identified]},
 doi = {10.1145/3177404.3177438},
 file = {http://dl.acm.org/citation.cfm?doid=3177404}
}


@article{Vaila.2019,
 author = {Vaila, Ruthvik and Chiasson, John and Saxena, Vishal},
 year = {2019},
 title = {Deep Convolutional Spiking Neural Networks for Image Classification},
 volume = {abs/1903.12272},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1903.12272}
}


@inproceedings{vanHorn.2018,
 author = {{van Horn}, Grant and {Mac Aodha}, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
 title = {The INaturalist Species Classification and Detection Dataset},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2018}
}


@proceedings{Verikas.2018,
 year = {2018},
 title = {Tenth International Conference on Machine Vision (ICMV 2017): 13-15 November 2017, Vienna, Austria},
 keywords = {Maschinelles Sehen},
 address = {Bellingham, Washington, USA},
 volume = {volume 10696},
 publisher = {SPIE},
 isbn = {9781510619418},
 series = {Proceedings of SPIE},
 editor = {Verikas, Antanas},
 institution = {{International Conference on Machine Vision} and SPIE and ICMV},
 file = {https://www.spiedigitallibrary.org/conference-proceedings-of-SPIE/10696.toc}
}


@inproceedings{Vo.2017,
 author = {Vo, An Tien and Tran, Hai Son and Le, Thai Hoang},
 title = {Advertisement image classification using convolutional neural network},
 pages = {197--202},
 publisher = {IEEE},
 isbn = {978-1-5386-3576-6},
 editor = {Nguyen, Thanh-Thuy},
 booktitle = {KSE 2017},
 year = {2017},
 address = {Piscataway, NJ},
 doi = {10.1109/KSE.2017.8119458},
 file = {http://ieeexplore.ieee.org/document/8119458/}
}


@book{Wallach.2019,
 year = {2019},
 title = {Advances in Neural Information Processing Systems 32},
 publisher = {{Curran Associates, Inc}},
 editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch{\'e}-Buc, F. d$\backslash$textquotesingle and Fox, E. and Garnett, R.}
}


@inproceedings{Wan.2013,
 abstract = {We introduce DropConnect, a generalization of DropOut, for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recoginition benchmarks can be obtained by aggregating multiple DropConnect-trained models.},
 author = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and {Le Cun}, Yann and Fergus, Rob},
 title = {Regularization of Neural Networks using DropConnect},
 url = {http://proceedings.mlr.press/v28/wan13.html},
 pages = {1058--1066},
 volume = {28},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 editor = {Dasgupta, Sanjoy and McAllester, David},
 booktitle = {Proceedings of the 30th International Conference on Machine Learning},
 year = {2013},
 address = {Atlanta, Georgia, USA}
}


@inproceedings{Wang.2017,
 author = {Wang, Fei and Jiang, Mengqing and Qian, Chen and Yang, Shuo and Li, Cheng and Zhang, Honggang and Wang, Xiaogang and Tang, Xiaoou},
 title = {Residual Attention Network for Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2017}
}


@inproceedings{Wang.2017b,
 author = {Wang, Xiaosong and Peng, Yifan and {Le Lu} and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
 title = {ChestX-ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2017}
}


@incollection{Wang.2018,
 author = {Wang, Bin and Sun, Yanan and Xue, Bing and Zhang, Mengjie},
 title = {A Hybrid Differential Evolution Approach to Designing Deep Convolutional Neural Networks for Image Classification},
 pages = {237--250},
 volume = {11320},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-030-03990-5},
 series = {Lecture Notes in Artificial Intelligence},
 editor = {Mitrovic, Tanja and Xue, Bing and Li, Xiaodong},
 booktitle = {AI 2018: Advances in Artificial Intelligence},
 year = {2018},
 address = {Cham},
 doi = {10.1007/978-3-030-03991-224}
}


@incollection{Wang.2018b,
 author = {Wang, Robert J. and Li, Xiang and Ling, Charles X.},
 title = {Pelee: A Real-Time Object Detection System on Mobile Devices},
 url = {http://papers.nips.cc/paper/7466-pelee-a-real-time-object-detection-system-on-mobile-devices.pdf},
 pages = {1963--1972},
 publisher = {{Curran Associates, Inc}},
 editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 31},
 year = {2018}
}


@inproceedings{Wang.2018c,
 author = {Wang, Yan and Xie, Lingxi and Qiao, Siyuan and Zhang, Ya and Zhang, Wenjun and Yuille, Alan L.},
 title = {Multi-Scale Spatially-Asymmetric Recalibration for Image Classification},
 editor = {Springer},
 booktitle = {The European Conference on Computer Vision (ECCV)},
 year = {2018}
}


@article{Wang.2019,
 author = {Wang, Xiao and Kihara, Daisuke and Luo, Jiebo and Qi, Guo-Jun},
 year = {2019},
 title = {EnAET: Self-Trained Ensemble AutoEncoding Transformations for Semi-Supervised Learning},
 url = {https://arxiv.org/abs/1911.09265v1},
 volume = {abs/1911.09265},
 journal = {ArXiv}
}


@inproceedings{Wang.2019b,
 author = {Wang, Yiru and Gan, Weihao and Yang, Jie and Wu, Wei and Yan, Junjie},
 title = {Dynamic Curriculum Learning for Imbalanced Data Classification},
 editor = {IEEE},
 booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 year = {2019}
}


@proceedings{Wilson.2016,
 year = {2016},
 title = {Procedings of the British Machine Vision Conference 2016},
 publisher = {{British Machine Vision Association}},
 isbn = {1-901725-59-6},
 editor = {Wilson, R. C. and Hancock, E. R. and Smith, W. A. P. and Pears, N. E. and Bors, A. G.},
 doi = {10.5244/C.30},
 file = {http://www.bmva.org/bmvc/2016/index.html}
}


@proceedings{Winter.2019,
 year = {2019},
 title = {2019 IEEE Winter Conference on Applications of Computer Vision (WACV)},
 editor = {Winter}
}


@proceedings{WorldScientific.2011,
 year = {2011},
 title = {IJCAI},
 editor = {{World Scientific}}
}


@inproceedings{Wu.2015,
 author = {Wu, Ruobing and Wang, Baoyuan and Wang, Wenping and Yu, Yizhou},
 title = {Harvesting Discriminative Meta Objects With Deep CNN Features for Scene Classification},
 editor = {IEEE},
 booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 year = {2015}
}


@inproceedings{Xiao.2015,
 author = {Xiao, Tianjun and Xu, Yichong and Yang, Kuiyuan and Zhang, Jiaxing and Peng, Yuxin and Zhang, Zheng},
 title = {The Application of Two-Level Attention Models in Deep Convolutional Neural Network for Fine-Grained Image Classification},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2015}
}


@article{Xie.2019,
 abstract = {Adversarial examples are commonly viewed as a threat to ConvNets. Here we present an opposite perspective: adversarial examples can be used to improve image recognition models if harnessed in the right manner. We propose AdvProp, an enhanced adversarial training scheme which treats adversarial examples as additional examples, to prevent overfitting. Key to our method is the usage of a separate auxiliary batch norm for adversarial examples, as they have different underlying distributions to normal examples.  We show that AdvProp improves a wide range of models on various image recognition tasks and performs better when the models are bigger. For instance, by applying AdvProp to the latest EfficientNet-B7 [28] on ImageNet, we achieve significant improvements on ImageNet (+0.7{\%}), ImageNet-C (+6.5{\%}), ImageNet-A (+7.0{\%}), Stylized-ImageNet (+4.8{\%}). With an enhanced EfficientNet-B8, our method achieves the state-of-the-art 85.5{\%} ImageNet top-1 accuracy without extra data. This result even surpasses the best model in [20] which is trained with 3.5B Instagram images ({\~{}}3000X more than ImageNet) and {\~{}}9.4X more parameters. Models are available at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
 author = {Xie, Cihang and Tan, Mingxing and Gong, Boqing and Wang, Jiang and Yuille, Alan and {Le V}, Quoc},
 year = {2019},
 title = {Adversarial Examples Improve Image Recognition},
 url = {http://arxiv.org/pdf/1911.09665v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1911.09665v1}
}


@article{Xie.2019b,
 author = {Xie, Qizhe and Hovy, Eduard H. and Luong, Minh-Thang and {Le V}, Quoc},
 year = {2019},
 title = {Self-training with Noisy Student improves ImageNet classification},
 url = {https://arxiv.org/abs/1911.04252v2},
 volume = {abs/1911.04252},
 journal = {ArXiv}
}


@incollection{Xie.2019c,
 author = {Xie, Yiting and Richmond, David},
 title = {Pre-training on Grayscale ImageNet Improves Medical Image Classification},
 pages = {476--484},
 volume = {11134},
 publisher = {Springer},
 isbn = {978-3-030-11023-9},
 series = {Lecture Notes in Computer Science},
 editor = {Leal-Taix{\'e}, Laura and Roth, Stefan},
 booktitle = {Computer vision - ECCV 2018 workshops},
 year = {2019},
 address = {Cham},
 doi = {10.1007/978-3-030-11024-637}
}


@misc{Xing.2019,
 author = {Xing, Jianfei and Zeng, Chenghua and Hu, Yangwen and Tao, Wanying and Mao, Yifan and Wang, Sida and Zheng, Yaojia and Wang, Ruixuan},
 year = {2019},
 title = {Open-Set Recognition of Dermoscopic Images with Ensemle of Deep Convolutional Networks},
 url = {https://isic-challenge-stade.s3.amazonaws.com/655ccf85-ba7b-4242-9f5a-3bbb7016bd71/ISIC2019_report.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=UYZjfbmYSqnfk%2FmcNAhimRkn5%2B4%3D&Expires=1584572948#page=1&zoom=auto,-17,792}
}


@article{Xiong.2019,
 author = {Xiong, Yunyang and Kim, Hyunwoo J. and Hedau, Varsha},
 year = {2019},
 title = {ANTNets: Mobile Convolutional Neural Networks for Resource Efficient  Image Classification},
 url = {http://arxiv.org/pdf/1904.03775.pdf},
 volume = {abs/1904.03775},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1904.03775}
}


@inproceedings{Xu.2019,
 author = {Xu, Hang and Yao, Lewei and Zhang, Wei and Liang, Xiaodan and Li, Zhenguo},
 title = {Auto-FPN: Automatic Network Architecture Adaptation for Object Detection Beyond Classification},
 editor = {IEEE},
 booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 year = {2019}
}


@inproceedings{Xu.2019b,
 author = {Xu, Lian and Bennamoun, Mohammed and Boussaid, Farid and An, Senjian and Sohel, Ferdous},
 title = {Coral Classification Using DenseNet and Cross-modality Transfer Learning},
 pages = {1--8},
 publisher = {[IEEE]},
 isbn = {978-1-7281-1985-4},
 editor = {IEEE},
 booktitle = {IJCNN 2019},
 year = {2019},
 address = {[Piscataway, New Jersey]},
 doi = {10.1109/IJCNN.2019.8852235},
 file = {https://ieeexplore.ieee.org/document/8852235/}
}


@article{Yamada.2019,
 author = {Yamada, Yoshihiro and Iwamura, Masakazu and Akiba, Takuya and Kise, Koichi},
 year = {2019},
 title = {Shakedrop Regularization for Deep Residual Learning},
 pages = {186126--186136},
 volume = {7},
 journal = {IEEE Access},
 doi = {10.1109/ACCESS.2019.2960566}
}


@inproceedings{Yang.2017,
 author = {Yang, Jufeng and She, Dongyu and Sun, Ming},
 title = {Joint Image Emotion Classification and Distribution Learning via Deep Convolutional Neural Network},
 pages = {3266--3272},
 publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
 isbn = {9780999241103},
 editor = {Bacchus, Fahiem and Sierra, Carles},
 booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence},
 year = {2017},
 address = {California},
 doi = {10.24963/ijcai.2017/456},
 file = {https://www.ijcai.org/proceedings/2017}
}


@inproceedings{Yang.2018,
 author = {Yang, Hong-Ming and Zhang, Xu-Yao and Yin, Fei and Liu, Cheng-Lin},
 title = {Robust Classification With Convolutional Prototype Learning},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2018}
}


@inproceedings{Yun.2019,
 author = {Yun, Sangdoo and Han, Dongyoon and Chun, Sanghyuk and Oh, Seong Joon and Yoo, Youngjoon and Choe, Junsuk},
 title = {CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features},
 pages = {6022--6031},
 publisher = {IEEE},
 isbn = {978-1-7281-4803-8},
 editor = {IEEE},
 booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
 year = {2019},
 doi = {10.1109/ICCV.2019.00612},
 file = {https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8972782}
}


@inproceedings{Zagoruyko.2016,
 author = {Zagoruyko, Sergey and Komodakis, Nikos},
 title = {Wide Residual Networks},
 pages = {87.1--87.12},
 publisher = {{British Machine Vision Association}},
 isbn = {1-901725-59-6},
 editor = {Wilson, R. C. and Hancock, E. R. and Smith, W. A. P. and Pears, N. E. and Bors, A. G.},
 booktitle = {Procedings of the British Machine Vision Conference 2016},
 year = {2016},
 doi = {10.5244/C.30.87},
 file = {http://www.bmva.org/bmvc/2016/index.html}
}


@article{Zahavy.2018,
 abstract = {Classifying products precisely and efficiently is a major challenge in modern e-commerce. The high traffic of new products uploaded daily and the dynamic nature of the categories raise the need for machine learning models that can reduce the cost and time of human editors. In this paper, we propose a decision level fusion approach for multi-modal product classification based on text and image neural network classifiers. We train input specific state-of-the-art deep neural networks for each input source, show the potential of forging them together into a multi-modal architecture and train a novel policy network that learns to choose between them. Finally, we demonstrate that our multi-modal network improves classification accuracy over both networks on a real-world large-scale product classification dataset that we collected from Walmart.com. While we focus on image-text fusion that characterizes e-commerce businesses, our algorithms can be easily applied to other modalities such as audio, video, physical sensors, etc.},
 author = {Zahavy, Tom and Krishnan, Abhinandan and Magnani, Alessandro and Mannor, Shie},
 year = {2018},
 title = {Is a Picture Worth a Thousand Words? A Deep Multi-Modal Architecture for Product Classification in E-Commerce},
 url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16579},
 journal = {AAAI Conference on Artificial Intelligence}
}


@inproceedings{Zeiler.2014,
 abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
 author = {Zeiler, Matthew D. and Fergus, Rob},
 title = {Visualizing and Understanding Convolutional Networks},
 pages = {818--833},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-319-10590-1},
 editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
 booktitle = {Computer Vision -- ECCV 2014},
 year = {2014},
 address = {Cham}
}


@article{Zhang.2016,
 abstract = {Unsupervised learning and supervised learning are key research topics in deep learning. However, as high-capacity supervised neural networks trained with a large amount of labels have achieved remarkable success in many computer vision tasks, the availability of large-scale labeled images reduced the significance of unsupervised learning. Inspired by the recent trend toward revisiting the importance of unsupervised learning, we investigate joint supervised and unsupervised learning in a large-scale setting by augmenting existing neural networks with decoding pathways for reconstruction. First, we demonstrate that the intermediate activations of pretrained large-scale classification networks preserve almost all the information of input images except a portion of local spatial details. Then, by end-to-end training of the entire augmented architecture with the reconstructive objective, we show improvement of the network performance for supervised tasks. We evaluate several variants of autoencoders, including the recently proposed {\textquotedbl}what-where{\textquotedbl} autoencoder that uses the encoder pooling switches, to study the importance of the architecture design. Taking the 16-layer VGGNet trained under the ImageNet ILSVRC 2012 protocol as a strong baseline for image classification, our methods improve the validation-set accuracy by a noticeable margin.},
 author = {Zhang, Yuting and Lee, Kibok and Lee, Honglak},
 year = {2016},
 title = {Augmenting Supervised Neural Networks with Unsupervised Objectives for  Large-scale Image Classification},
 url = {http://arxiv.org/pdf/1606.06582v1},
 keywords = {Computer Science - Computer Vision and Pattern Recognition;Computer Science - Learning},
 journal = {PMLR 48:612-621},
 file = {http://arxiv.org/abs/1606.06582v1}
}


@inproceedings{Zhang.2016b,
 author = {Zhang, Hua and Liu, Si and Zhang, Changqing and Ren, Wenqi and Wang, Rui and Cao, Xiaochun},
 title = {SketchNet: Sketch Classification With Web Images},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2016}
}


@incollection{Zhang.2018,
 author = {Zhang, Liheng and Edraki, Marzieh and Qi, Guo-Jun},
 title = {CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces},
 url = {http://papers.nips.cc/paper/7823-cappronet-deep-feature-learning-via-orthogonal-projections-onto-capsule-subspaces.pdf},
 pages = {5814--5823},
 publisher = {{Curran Associates, Inc}},
 editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
 booktitle = {Advances in Neural Information Processing Systems 31},
 year = {2018}
}


@article{Zhang.2018b,
 author = {Zhang, Zhi and Ning, Guanghan and Cen, Yigang and Li, Yang and Zhao, Zhiqun and Sun, Hao and He, Zhihai},
 year = {2018},
 title = {Progressive Neural Networks for Image Classification},
 volume = {abs/1804.09803},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1804.09803}
}


@article{Zhang.2019,
 author = {Zhang, Hongyi and Dauphin, Yann and Ma, Tengyu},
 year = {2019},
 title = {Fixup Initialization: Residual Learning Without Normalization},
 url = {https://arxiv.org/abs/1901.09321v2},
 volume = {abs/1901.09321},
 journal = {ArXiv}
}


@misc{Zhang.2019b,
 author = {Zhang, Pengyi and Zhong, Yunxin and Li, Xiaoqiong},
 year = {2019},
 title = {MelaNet A Deep Dense Attention Networkfor Melanoma Detection in DermoscopyImages},
 url = {https://isic-challenge-stade.s3.amazonaws.com/ec32574f-cce5-4dff-a24a-47016d03808a/ISIC2019_description_zhangpy-03.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=Gp5ASXT68nXyzYhUTUQv9TPgq5Y%3D&Expires=1584572948}
}


@article{Zhang.2019c,
 author = {Zhang, Yu-Dong and Dong, Zhengchao and Chen, Xianqing and Jia, Wenjuan and Du, Sidan and Muhammad, Khan and Wang, Shui-Hua},
 year = {2019},
 title = {Image based fruit category classification by 13-layer deep convolutional neural network and data augmentation},
 pages = {3613--3632},
 volume = {78},
 number = {3},
 issn = {1380-7501},
 journal = {Multimedia Tools and Applications},
 doi = {10.1007/s11042-017-5243-3}
}


@article{Zhao.2015,
 author = {Zhao, Junbo Jake and Mathieu, Micha{\"e}l and Goroshin, Ross and LeCun, Yann},
 year = {2015},
 title = {Stacked What-Where Auto-encoders},
 url = {https://arxiv.org/abs/1506.02351v8},
 volume = {abs/1506.02351},
 journal = {CoRR}
}


@inproceedings{Zhao.2018,
 author = {Zhao, Xin and Wang, Xianheng and Wang, Hongkai},
 title = {Classification of Benign and Malignant Breast Mass in Digital Mammograms with Convolutional Neural Networks},
 pages = {47--50},
 publisher = {{The Association for Computing Machinery}},
 isbn = {9781450365338},
 series = {ICPS},
 editor = {ACM},
 booktitle = {ISICDM 2018},
 year = {2018},
 address = {New York, New York},
 doi = {10.1145/3285996.3286006},
 file = {http://dl.acm.org/citation.cfm?doid=3285996}
}


@article{Zhong.2017,
 author = {Zhong, Zhun and Zheng, Liang and Kang, Guoliang and Li, Shaozi and Yang, Yi},
 year = {2017},
 title = {Random Erasing Data Augmentation},
 volume = {abs/ 1708.04896},
 journal = {ArXiv}
}


@proceedings{Zhou.2015,
 year = {2015},
 title = {MM'15: Proceedings of the 2015 ACM Multimedia Conference : October 26-30, 2015, Brisbane, Australia},
 address = {New York, New York, USA},
 publisher = {{ACM Press}},
 isbn = {9781450334594},
 editor = {Zhou, Xiaofang and Smeaton, Alan F. and Tian, Qi and Bulterman, Dick C.A. and Shen, Heng Tao and Mayer-Patel, Ketan and Yan, Shuicheng},
 institution = {{ACM Multimedia Conference} and {Association for Computing Machinery} and {ACM Multimedia} and {ACM MM} and ACMMM and MM and {MM Doctoral Symposium}},
 doi = {10.1145/2733373}
}


@inproceedings{Zhou.2017,
 author = {Zhou, Yiren and Song, Sibo and Cheung, Ngai-Man},
 title = {On Classification of Distorted Images with Deep Convolutional Neural  Networks},
 pages = {1213--1217},
 publisher = {IEEE},
 isbn = {978-1-5090-4117-6},
 editor = {IEEE},
 booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
 year = {2017},
 doi = {10.1109/ICASSP.2017.7952349},
 file = {http://ieeexplore.ieee.org/document/7952349/}
}


@misc{Zhou.2019,
 author = {Zhou, Steven and Zhuang, Yixin and Meng, Rusong},
 year = {2019},
 title = {Multi-Category Skin Lesion Diagnosis Using Dermoscopy Images and Deep CNN Ensembles},
 url = {https://isic-challenge-stade.s3.amazonaws.com/9e2e7c9c-480c-48dc-a452-c1dd577cc2b2/ISIC2019-paper-0816.pdf?AWSAccessKeyId=AKIA2FPBP3II4S6KTWEU&Signature=5CjJscpLoivDjAVxDQVnMb9LPfE%3D&Expires=1584572948}
}


@inproceedings{Zhu.2015,
 author = {Zhu, Yi and Newsam, Shawn},
 title = {Land use classification using convolutional neural networks applied to ground-level images},
 pages = {1--4},
 publisher = {{The Association for Computing Machinery, Inc}},
 isbn = {9781450339674},
 editor = {Ali, Mohamed},
 booktitle = {23rd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS 2015)},
 year = {2015},
 address = {New York, NY},
 doi = {10.1145/2820783.2820851},
 file = {http://dl.acm.org/citation.cfm?doid=2820783}
}


@inproceedings{Zhu.2016,
 author = {Zhu, Zhe and Liang, Dun and Zhang, Songhai and Huang, Xiaolei and Li, Baoli and Hu, Shimin},
 title = {Traffic-Sign Detection and Classification in the Wild},
 editor = {IEEE},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2016}
}


@article{Zhuang.2018,
 author = {Zhuang, Bohan and Shen, Chunhua and Tan, Mingkui and Liu, Lingqiao and Reid, Ian D.},
 year = {2018},
 title = {Structured Binary Neural Networks for Accurate Image Classification  and Semantic Segmentation},
 url = {http://arxiv.org/pdf/1811.10413v2},
 volume = {abs/1811.10413},
 journal = {CoRR},
 file = {http://arxiv.org/abs/1811.10413}
}


% Nachtrglich hinzugefgt
@inproceedings{imagenet.2019,
	AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
	TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
	BOOKTITLE = {CVPR09},
	YEAR = {2009},
	BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}

@article{cifar.2012,
	author = {Krizhevsky, Alex},
	year = {2012},
	month = {05},
	pages = {},
	title = {Learning Multiple Layers of Features from Tiny Images},
	journal = {University of Toronto}
}

@article{mnist.2010,
	title={MNIST handwritten digit database},
	author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
	journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
	volume={2},
	year={2010}
}


@inproceedings{svhn.2011,
	title	= {Reading Digits in Natural Images with Unsupervised Feature Learning},
	author	= {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
	year	= {2011},
	URL	= {http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf},
	booktitle	= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}

@inproceedings{stl.2011,
	title={An analysis of single-layer networks in unsupervised feature learning},
	author={Coates, Adam and Ng, Andrew and Lee, Honglak},
	booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
	pages={215--223},
	year={2011}
}

@inproceedings{clothing.2016,
	author = {Liu, Ziwei and Luo, Ping and Qiu, Shi and Wang, Xiaogang and Tang, Xiaoou},
	title = {DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations},
	booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2016} 
}

@article{fashionMNIST.2017,
	author    = {Han Xiao and
	Kashif Rasul and
	Roland Vollgraf},
	title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning
	Algorithms},
	journal   = {CoRR},
	volume    = {abs/1708.07747},
	year      = {2017},
	url       = {http://arxiv.org/abs/1708.07747},
	archivePrefix = {arXiv},
	eprint    = {1708.07747},
	timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{flowers.2008,
	author = {Nilsback, M-E. and Zisserman, A.},
	title = {Automated Flower Classification over a Large Number of Classes},
	booktitle = {Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing},
	year = {2008},
}

@inproceedings{food.2014,
	title = {Food-101 -- Mining Discriminative Components with Random Forests},
	author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
	booktitle = {European Conference on Computer Vision},
	year = {2014}
}

@inproceedings{stanfordcars.2013,
	title = {3D Object Representations for Fine-Grained Categorization},
	booktitle = {4th International IEEE Workshop on  3D Representation and Recognition (3dRR-13)},
	year = {2013},
	address = {Sydney, Australia},
	author = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}
}

@article{emnistletters.2017,
	title={EMNIST: Extending MNIST to handwritten letters},
	DOI={10.1109/ijcnn.2017.7966217},
	journal={2017 International Joint Conference on Neural Networks (IJCNN)},
	author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Schaik, Andre Van},
	year={2017}
}



@article{kuzushijiMNIST.2018,
	author    = {Tarin Clanuwat and
	Mikel Bober{-}Irizar and
	Asanobu Kitamoto and
	Alex Lamb and
	Kazuaki Yamamoto and
	David Ha},
	title     = {Deep Learning for Classical Japanese Literature},
	journal   = {CoRR},
	volume    = {abs/1812.01718},
	year      = {2018},
	url       = {http://arxiv.org/abs/1812.01718},
	archivePrefix = {arXiv},
	eprint    = {1812.01718},
	timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1812-01718.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@techreport{cub.2011,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}


@misc{isic1.2019,
	title={BCN20000: Dermoscopic Lesions in the Wild},
	author={Marc Combalia and Noel C. F. Codella and Veronica Rotemberg and Brian Helba and Veronica Vilaplana and Ofer Reiter and Cristina Carrera and Alicia Barreiro and Allan C. Halpern and Susana Puig and Josep Malvehy},
	year={2019},
	eprint={1908.02288},
	archivePrefix={arXiv},
	primaryClass={eess.IV}
}

@inproceedings{isic2.2018, author={N. C. F. {Codella} and D. {Gutman} and M. E. {Celebi} and B. {Helba} and M. A. {Marchetti} and S. W. {Dusza} and A. {Kalloo} and K. {Liopyris} and N. {Mishra} and H. {Kittler} and A. {Halpern}}, booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, title={Skin lesion analysis toward melanoma detection: A challenge at the 2017 International symposium on biomedical imaging (ISBI), hosted by the international skin imaging collaboration (ISIC)}, year={2018}, volume={}, number={}, pages={168-172},} 


@article{isic3.2018,
	author = {Tschandl, Philipp and Rosendahl, Cliff and Kittler, Harald},
	year = {2018},
	title = {The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions},
	pages = {180161},
	volume = {5},
	journal = {Scientific data},
	doi = {10.1038/sdata.2018.161},
	file = {http://www.ncbi.nlm.nih.gov/pubmed/30106392},
	file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6091241}
}

@incollection{Bansal.2019b,
	author = {Bansal, Dipali and Mahajan, Rashima},
	title = {Chapter 2 - EEG-Based Brain-Computer Interfacing (BCI)},
	url = {http://www.sciencedirect.com/science/article/pii/B9780128146873000028},
	keywords = {Acquisition techniques;Brain-computer interface;Classification of brain signals;Control applications;Electroencephalogram;feature extraction},
	pages = {21--71},
	publisher = {{Academic Press}},
	isbn = {978-0-12-814687-3},
	editor = {Bansal, Dipali and Mahajan, Rashima},
	booktitle = {EEG-Based Brain-Computer Interfaces},
	year = {2019},
	doi = {10.1016/B978-0-12-814687-3.00002-8}
}

@article{Webster.2002,
	ISSN = {02767783},
	URL = {http://www.jstor.org/stable/4132319},
	author = {Jane Webster and Richard T. Watson},
	journal = {MIS Quarterly},
	number = {2},
	pages = {xiii--xxiii},
	publisher = {Management Information Systems Research Center, University of Minnesota},
	title = {Analyzing the Past to Prepare for the Future: Writing a Literature Review},
	volume = {26},
	year = {2002}
}


@book{Mohri.2012,
	author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
	year = {2012},
	title = {Foundations of machine learning},
	keywords = {Computer algorithms;K{\"u}nstliche Intelligenz;Machine learning;Maschinelles Lernen;Maschinelles Sehen},
	address = {Cambridge, Mass. and London},
	publisher = {{The MIT Press}},
	isbn = {9780262018258},
	series = {Adaptive computation and machine learning}
}


@article{Hornik.1989,
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	year = {1989},
	title = {Multilayer feedforward networks are universal approximators},
	url = {https://www.sciencedirect.com/science/article/abs/pii/0893608089900208?via%3Dihub},
	pages = {359--366},
	volume = {2},
	number = {5},
	issn = {08936080},
	journal = {Neural Networks},
	doi = {10.1016/0893-6080(89)90020-8}
}

@article{LeCun.2015b,
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year = {2015},
	title = {Deep learning},
	url = {https://www.nature.com/articles/nature14539},
	pages = {436--444},
	volume = {521},
	number = {7553},
	journal = {Nature},
	doi = {10.1038/nature14539}
}


@book{Ertel.2016,
	title={Grundkurs k{\"u}nstliche Intelligenz: eine praxisorientierte Einf{\"u}hrung},
	author={Ertel, Wolfgang},
	year={2016},
	publisher={Springer-Verlag}
}


@incollection{Black.2016,
	author = {Black, Paul E.},
	title = {array},
	url = {https://xlinux.nist.gov/dads/HTML/array.html},
	publisher = {National Institute of Standards and Technology},
	booktitle = {Dictionary of Algorithms and Data Structures},
	year = {2016}
}


@article{Garcia.2005,
	author = {Garcia, Ronald and Lumsdaine, Andrew},
	year = {2005},
	title = {MultiArray: a C++ library for generic programming with arrays},
	pages = {159--188},
	volume = {35},
	number = {2},
	issn = {0038-0644},
	journal = {Software: Practice and Experience},
	doi = {10.1002/spe.630}
}


@inproceedings{Castro.2010, author={P. {de Oliveira Castro} and S. {Louise} and D. {Barthou}}, booktitle={2010 International Conference on Complex, Intelligent and Software Intensive Systems}, title={A Multidimensional Array Slicing DSL for Stream Programming}, year={2010}, volume={}, number={}, pages={913-918},} 


@book{Goodfellow.2016,
	title={Deep Learning},
	author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	publisher={MIT Press},
	note={\url{http://www.deeplearningbook.org}},
	year={2016}
}



@book{ElAmir.2020,
	author = {El-Amir, Hisham and Hamdy, Mahmoud},
	year = {2020},
	title = {Deep Learning Pipeline: Building a Deep Learning Model with TensorFlow},
	url = {https://doi.org/10.1007/978-1-4842-5349-6},
	edition = {1st ed. 2020},
	isbn = {978-1-4842-5349-6},
	file = {http://media.obvsg.at/AC15553045-1001}
}


@article{Svozil.1997,
	author = {Svozil, Daniel and Kvasnicka, Vladim{\'i}r and Pospichal, Jir{\'i}},
	year = {1997},
	title = {Introduction to multi-layer feed-forward neural networks},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S0169743997000610?via%3Dihub},
	pages = {43--62},
	volume = {39},
	number = {1},
	issn = {0169-7439},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	doi = {10.1016/S0169-7439(97)00061-0}
}

@book{Singh.2020,
	author = {Singh, Pramod and Manure, Avinash},
	year = {2020},
	title = {Learn TensorFlow 2.0: Implement Machine Learning and Deep Learning Models with Python},
	url = {https://doi.org/10.1007/978-1-4842-5558-2},
	edition = {1st ed. 2020},
	isbn = {978-1-4842-5558-2},
	file = {http://media.obvsg.at/AC15552986-1001}
}


@book{Michelucci.2019,
	author = {Michelucci, Umberto},
	year = {2019},
	title = {Advanced applied deep learning: Convolutional neural networks and object detection},
	address = {New York},
	publisher = {Apress},
	isbn = {978-1-4842-4975-8},
	file = {http://www.worldcat.org/oclc/1121582523}
}


@InProceedings{Xie.2017,
	author = {Xie, Saining and Girshick, Ross and Dollar, Piotr and Tu, Zhuowen and He, Kaiming},
	title = {Aggregated Residual Transformations for Deep Neural Networks},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2017}
} 



@InProceedings{Ioffe.2015,
	title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	author = 	 {Sergey Ioffe and Christian Szegedy},
	booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
	pages = 	 {448--456},
	year = 	 {2015},
	editor = 	 {Francis Bach and David Blei},
	volume = 	 {37},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Lille, France},
	publisher = 	 {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v37/ioffe15.pdf},
	url = 	 {http://proceedings.mlr.press/v37/ioffe15.html},
}


@inproceedings{Santurkar.2018,
	title={How Does Batch Normalization Help Optimization?},
	author={Shibani Santurkar and Dimitris Tsipras and Andrew Ilyas and Aleksander Madry},
	booktitle={NeurIPS},
	year={2018}
}

@InProceedings{Szegedy.2016,
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	title = {Rethinking the Inception Architecture for Computer Vision},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2016}
} 

@article{Chollet.2017,
	title={Xception: Deep Learning with Depthwise Separable Convolutions},
	author={Franois Chollet},
	journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2017},
	pages={1800-1807}
}


@article{Guo.2019,
	author = {Guo, Yunhui and Li, Yandong and Wang, Liqiang and Rosing, Tajana},
	year = {2019},
	title = {Depthwise Convolution Is All You Need for Learning Multiple Visual Domains},
	pages = {8368--8375},
	volume = {33},
	issn = {2159-5399},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	doi = {10.1609/aaai.v33i01.33018368},
}


@article{Srivastava.2014,
	title={Dropout: a simple way to prevent neural networks from overfitting},
	author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal={The journal of machine learning research},
	volume={15},
	number={1},
	pages={1929--1958},
	year={2014},
	publisher={JMLR. org}
}

@article{Rumelhart.1986,
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	year = {1986},
	title = {Learning representations by back-propagating errors},
	url = {https://www.nature.com/articles/323533a0},
	pages = {533--536},
	volume = {323},
	number = {6088},
	journal = {Nature},
	doi = {10.1038/323533a0}
}

@book{Python3,
	author = {Van Rossum, Guido and Drake, Fred L.},
	title = {Python 3 Reference Manual},
	year = {2009},
	isbn = {1441412697},
	publisher = {CreateSpace},
	address = {Scotts Valley, CA}
} 

@misc{Keras,
	title={Keras},
	author={Chollet, Fran\c{c}ois and others},
	year={2015},
	publisher={GitHub},
	url={https://github.com/fchollet/keras},
}

@misc{Tensorflow.2015,
	title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={https://www.tensorflow.org/},
	note={Software available from tensorflow.org},
	author={
	Mart\'{\i}n~Abadi and
	Ashish~Agarwal and
	Paul~Barham and
	Eugene~Brevdo and
	Zhifeng~Chen and
	Craig~Citro and
	Greg~S.~Corrado and
	Andy~Davis and
	Jeffrey~Dean and
	Matthieu~Devin and
	Sanjay~Ghemawat and
	Ian~Goodfellow and
	Andrew~Harp and
	Geoffrey~Irving and
	Michael~Isard and
	Yangqing Jia and
	Rafal~Jozefowicz and
	Lukasz~Kaiser and
	Manjunath~Kudlur and
	Josh~Levenberg and
	Dandelion~Man\'{e} and
	Rajat~Monga and
	Sherry~Moore and
	Derek~Murray and
	Chris~Olah and
	Mike~Schuster and
	Jonathon~Shlens and
	Benoit~Steiner and
	Ilya~Sutskever and
	Kunal~Talwar and
	Paul~Tucker and
	Vincent~Vanhoucke and
	Vijay~Vasudevan and
	Fernanda~Vi\'{e}gas and
	Oriol~Vinyals and
	Pete~Warden and
	Martin~Wattenberg and
	Martin~Wicke and
	Yuan~Yu and
	Xiaoqiang~Zheng},
	year={2015},
}


@misc{CUDA,
	year = {2007},
	title = {CUDA Technology},
	author = {NVIDEA},
	publisher = {NVIDEA},
	url = {https://developer.nvidia.com/cuda-toolkit}
}


@article{cuDNN,
	title={cuDNN: Efficient Primitives for Deep Learning},
	author={Sharan Chetlur and Cliff Woolley and Philippe Vandermersch and Jonathan Cohen and John Tran and Bryan Catanzaro and Evan Shelhamer},
	journal={ArXiv},
	year={2014},
	volume={abs/1410.0759}
}


@misc{Statista.2019,
	year = {2019},
	title = {In-depth: Industry 4.0 2019 Statista Digital Market Outlook},
	author = {Statista},
	publisher = {Statista},
	url = {https://de.statista.com/statistik/studie/id/67366/dokument/in-depth-industry-40/}
}


@misc{Shook.2019,
	title = {Harnessing Revolution Creating the future workforce},
	author = {Ellyn Shook and Mark Knickrehm},
	publisher = {Accenture},
	year = {2017},
	url = {https://www.accenture.com/_acnmedia/pdf-40/accenture-strategy-harnessing-revolution-pov.pdf}
}

@misc{Guy.2019,
	title = {The coming evolution of field operations},
	author = {Benjamin Guy and May Brett and Prema Mitesh and Raghubansh Vaibhaw},
	publisher = {McKinsey & Company},
	year = {2019},
	url = {https://www.mckinsey.com/~/media/McKinsey/Business%20Functions/Operations/Our%20Insights/The%20coming%20evolution%20of%20field%20operations/The-coming-evolution-of-field-operations.ashx}
}

@misc{Detzel.2018,
	title = {Rolling Out Augmented Reality in the Field},
	author = {Christopher Detzel and Amit Kumar and Sesh Iyer and Vikas Taneja},
	publisher = {Boston Consulting Group},
	year = {2018},
	url = {https://www.bcg.com/de-de/publications/2018/rolling-out-augmented-reality-field.aspx}
}

@misc{EY.2019a,
	title = {Stop talking about the future of work},
	author = {{Ernst \& Young}},
	publisher = {{Ernst \& Young}},
	year = {2019},
	url = {https://assets.ey.com/content/dam/ey-sites/ey-com/en_au/topics/campaigns/future-of-work/stop-talking-about-future-of-work.pdf}
}

@misc{EY.2019b,
	title = {The Future of Work: the Changing Skills Landscape for Miners},
	author = {{Ernst \& Young}},
	publisher = {{Ernst \& Young}},
	year = {2019},
	url = {https://minerals.org.au/sites/default/files/190214%20The%20Future%20of%20Work%20the%20Changing%20Skills%20Landscape%20for%20Miners.pdf}
}


@misc{Honeywell.2018a,
	title = {The Honeywell Connected Plant},
	author = {Paul Bonner},
	publisher = {{Honeywell International  Inc.}},
	year = {2018},
	url = {https://www.honeywellprocess.com/library/news-and-events/presentations/hug-america-2018-honeywell-connected-plant-introduction.pdf},
	urldate= {27/04/2020}
}


@misc{Honeywell.2018b,
	title = {Honeywell Connected Worker Solutionss},
	author = {{Honeywell International  Inc.}},
	publisher = {{Honeywell International  Inc.}},
	year = {2018},
	url = {https://www.honeywellaidc.com/solutions/connected-worker},
	urldate= {27/04/2020}
}


@book{Gad.2018,
	author = {Gad, Ahmed Fawzy},
	year = {2018},
	title = {Practical Computer Vision Applications Using Deep Learning with CNNs: With Detailed Examples in Python Using TensorFlow and Kivy},
	publisher = {Apress},
	isbn = {9781484241684},
	doi = {10.1007/978-1-4842-4167-7}
}


@book{Kapur.2017,
	author = {Kapur, Saurabh},
	year = {2017},
	title = {Computer vision with Python 3: Image classification, object detection, video processing, and more},
	address = {Birmingham, UK},
	publisher = {{Packt Publishing}},
	isbn = {9781788299763}
}


@article{Schaul.2010,
	author = {Schaul, Tom and Schmidhuber, Juergen},
	year = {2010},
	title = {Metalearning},
	pages = {4650},
	volume = {5},
	number = {6},
	journal = {Scholarpedia},
	doi = {10.4249/scholarpedia.4650}
}


@article{Pan.2010,
	author = {Pan, Sinno Jialin and Yang, Qiang},
	year = {2010},
	title = {A Survey on Transfer Learning},
	url = {https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf},
	pages = {1345--1359},
	volume = {22},
	number = {10},
	issn = {1041-4347},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	doi = {10.1109/TKDE.2009.191}
}


@article{Szegedy.2014,
	title={Intriguing properties of neural networks},
	author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian J. Goodfellow and Rob Fergus},
	journal={CoRR},
	year={2014},
	volume={abs/1312.6199}
}


@article{Caruana.1997,
	author = {Caruana, Rich},
	year = {1997},
	title = {Multitask Learning},
	pages = {41--75},
	volume = {28},
	number = {1},
	issn = {08856125},
	journal = {Machine Learning},
	doi = {10.1023/A:1007379606734}
}


@article{Tieleman.2012,
	title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
	author={Tieleman, Tijmen and Hinton, Geoffrey},
	journal={COURSERA: Neural networks for machine learning},
	volume={4},
	number={2},
	pages={26--31},
	year={2012}
}

@article{Ruder.2016,
	title={An overview of gradient descent optimization algorithms},
	author={Ruder, Sebastian},
	journal={arXiv preprint arXiv:1609.04747},
	year={2016}
} 

@article{Elfwing.2018,
	title={Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning},
	author={Stefan Elfwing and Eiji Uchibe and Kenji Doya},
	journal={Neural networks : the official journal of the International Neural Network Society},
	year={2018},
	volume={107},
	pages={
	3-11
	}
}

@article{Ramachandran.2017,
	title={Swish: a Self-Gated Activation Function},
	author={Prajit Ramachandran and Barret Zoph and Quoc V. Le},
	journal={arXiv: Neural and Evolutionary Computing},
	year={2017}
}


@article{Yuan.2019,
	title={Object-Contextual Representations for Semantic Segmentation},
	author={Yuhui Yuan and Xilin Chen and Jingdong Wang},
	journal={ArXiv},
	year={2019},
	volume={abs/1909.11065}
}

@article{Tan.2019b,
	title={EfficientDet: Scalable and Efficient Object Detection},
	author={Mingxing Tan and Ruoming Pang and Quoc V. Le},
	journal={ArXiv},
	year={2019},
	volume={abs/1911.09070}
}

@article{Karras.2018,
	title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},
	author={Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
	journal={ArXiv},
	year={2018},
	volume={abs/1710.10196}
}

@article{Bulat.2020,
	title={Toward fast and accurate human pose estimation via soft-gated skip connections},
	author={Adrian Bulat and Jean Kossaifi and Georgios Tzimiropoulos and Maja Pantic},
	journal={ArXiv},
	year={2020},
	volume={abs/2002.11098}
}

@article{Yan.2019,
	title={VarGFaceNet: An Efficient Variable Group Convolutional Neural Network for Lightweight Face Recognition},
	author={Mengjia Yan and Mengao Zhao and Zining Xu and Qian Zhang and Guoli Wang and Zhizhong Su},
	journal={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
	year={2019},
	pages={2647-2654}
}

@misc{AWS.2020a,
	title = {AWS Deep Learning AMI (Ubuntu 18.04)},
	author = {{Amazon Web Services, Inc.}},
	publisher = {{Amazon Web Services, Inc.}},
	year = {2020},
	url = {https://aws.amazon.com/marketplace/pp/Amazon-Web-Services-AWS-Deep-Learning-AMI-Ubuntu-1/B07Y43P7X5}
}

@misc{AWS.2020b,
	title = {Amazon EC2 G4 Instances},
	author = {{Amazon Web Services, Inc.}},
	publisher = {{Amazon Web Services, Inc.}},
	year = {2020},
	url = {https://aws.amazon.com/de/ec2/instance-types/g4/}
	
}

@misc{KerasApp,
	title={Keras Applications},
	author={Chollet, Fran\c{c}ois and others},
	year={2015},
	publisher={GitHub},
	url={https://github.com/keras-team/keras-applications},
}